{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import videoseal \n",
    "from IPython.display import HTML, display\n",
    "from base64 import b64encode\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import logging\n",
    "logging.getLogger(\"matplotlib.image\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fps = 24 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the VideoSeal Model\n",
    "The videoseal library provides pretrained models for embedding and extracting watermarks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VideoSeal model\n",
    "model = videoseal.load(\"videoseal\")\n",
    "\n",
    "# Set the model to evaluation mode and move it to the selected device\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess the Video\n",
    "We will process a single video. For demonstration, the video is trimmed to the first 3 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the input video\n",
    "video_path = \"./assets/videos/2.mp4\"\n",
    "\n",
    "# Read the video and convert to tensor format\n",
    "video, _, _ = torchvision.io.read_video(video_path, output_format=\"TCHW\")\n",
    "\n",
    "# Normalize the video frames to the range [0, 1] and trim to 1 second\n",
    "video = video[:fps * 5].float() / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videoseal Embedder: Embed the Watermark\n",
    "The model embeds a watermark into the video frames. This step generates the watermarked frames (imgs_w) and returns the random watermark message (msgs) so you know which message was embedded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform watermark embedding\n",
    "outputs = model.embed(video, is_video=True)\n",
    "\n",
    "# Extract the results\n",
    "video_w = outputs[\"imgs_w\"]  # Watermarked video frames\n",
    "msgs = outputs[\"msgs\"]      # Watermark messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference between watermarked and original frames\n",
    "diff = video - video_w\n",
    "\n",
    "# Normalize the difference for visualization\n",
    "min_vals = diff.view(diff.shape[0], diff.shape[1], -1).min(dim=2, keepdim=True)[0].view(diff.shape[0], diff.shape[1], 1, 1)\n",
    "max_vals = diff.view(diff.shape[0], diff.shape[1], -1).max(dim=2, keepdim=True)[0].view(diff.shape[0], diff.shape[1], 1, 1)\n",
    "normalized_images = (diff - min_vals) / (max_vals - min_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display The Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_videos_side_by_side(videos, titles):\n",
    "    \"\"\"\n",
    "    Display multiple videos side by side in a table format in a Jupyter Notebook.\n",
    "\n",
    "    Args:\n",
    "    - videos: List of video tensors (torch.Tensor).\n",
    "    - titles: List of column titles corresponding to the videos.\n",
    "    \"\"\"\n",
    "    # Prepare video HTML strings\n",
    "    video_htmls = []\n",
    "    for video in videos:\n",
    "\n",
    "        video = video.permute(0, 2, 3, 1).cpu().numpy()  # Convert to numpy format\n",
    "                \n",
    "        # resize and display 2 secs only \n",
    "        video = video[:fps*2]\n",
    "\n",
    "        _, C, H, W = video.shape\n",
    "        new_H, new_W = 512, int((512 / H) * W)\n",
    "        new_H, new_W = (new_H // 2) * 2, (new_W // 2) * 2  # Ensure even dimensions\n",
    "        # Resize the video\n",
    "        video = F.resize(video, (new_H, new_W))\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        img = ax.imshow(video_np[0])  # Display the first frame\n",
    "\n",
    "        # Remove axis ticks and labels\n",
    "        ax.axis('off')\n",
    "\n",
    "        def update(frame):\n",
    "            img.set_data(video_np[frame])\n",
    "            return img,\n",
    "\n",
    "        ani = FuncAnimation(fig, update, frames=len(video_np), interval=1000 // fps)\n",
    "        plt.close(fig)\n",
    "        video_htmls.append(ani.to_jshtml())\n",
    "    \n",
    "    # Create table with titles as headers and videos as content\n",
    "    table_html = '<table style=\"width:100%; text-align:center; border-collapse: collapse;\">'\n",
    "    table_html += '<tr>'  # Row for headers\n",
    "    for title in titles:\n",
    "        table_html += f'<th style=\"border: 1px solid black; padding: 5px;\">{title}</th>'\n",
    "    table_html += '</tr>'\n",
    "    table_html += '<tr>'  # Row for videos\n",
    "    for video_html in video_htmls:\n",
    "        table_html += f'<td style=\"border: 1px solid black; padding: 5px;\">{video_html}</td>'\n",
    "    table_html += '</tr>'\n",
    "    table_html += '</table>'\n",
    "    \n",
    "    return HTML(table_html)\n",
    "\n",
    "# Display the videos side by side\n",
    "videos = [video, video_w, normalized_images]\n",
    "titles = [\"Original Video\", \"Watermarked Video\", \"Watermark\"]\n",
    "display(display_videos_side_by_side(videos, titles))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videoseal Extractor: Extract the Watermark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoseal.evals.metrics import bit_accuracy\n",
    "\n",
    "msg_extracted = model.extract_message(video_w)\n",
    "\n",
    "bit_accuracy_ = bit_accuracy(msg_extracted, msgs).nanmean().item()\n",
    "print(f\"Bit Accuracy: {bit_accuracy_:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test VideoSeal Robustness to H264 Codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from videoseal.augmentation import H264\n",
    "\n",
    "def compress_and_eval(video_w, msgs, compression_levels):\n",
    "    \"\"\"\n",
    "    Test the watermark resistance to H.264 compression.\n",
    "    \n",
    "    Args:\n",
    "    - video_w (torch.Tensor): Watermarked video frames.\n",
    "    - msgs (torch.Tensor): Original watermark messages.\n",
    "    - compression_levels (list): List of CRF values for compression.\n",
    "    \n",
    "    Returns:\n",
    "    - results (list): List of dictionaries containing CRF, Bit Accuracy, and Detection Time.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    h264 = H264()  # H.264 compression augmentation\n",
    "\n",
    "    for crf in compression_levels:\n",
    "        # Apply H.264 compression\n",
    "        video_compressed, _ = h264(video_w, crf=crf)\n",
    "\n",
    "        # Detect watermarks in the compressed video        \n",
    "        outputs = model.detect(video_compressed, is_video=True)\n",
    "\n",
    "        # Compute bit accuracy\n",
    "        preds = outputs[\"preds\"]\n",
    "        bit_preds = preds[:, 1:]  # Extract watermark bits\n",
    "        bit_acc = bit_accuracy(bit_preds, msgs).nanmean().item()\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"CRF\": crf,\n",
    "            \"Bit Accuracy\": round(bit_acc, 3),\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Test the watermark resistance at different CRF levels\n",
    "compression_levels = [15, 23, 30, 32, 35, 38, 40, 60]  # CRF values for H.264 compression\n",
    "results = compress_and_eval(video_w, msgs, compression_levels)\n",
    "\n",
    "# Display results in a table\n",
    "df_results = pd.DataFrame(results)\n",
    "display(HTML(\"<h3>Watermark Resistance to Compression</h3>\"))\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videoseal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
