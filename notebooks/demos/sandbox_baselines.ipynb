{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/09-videoseal/baselines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoseal.utils.display import save_vid\n",
    "from videoseal.utils import Timer\n",
    "# from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy, psnr, pvalue, capacity\n",
    "# from videoseal.data.datasets import VideoDataset\n",
    "from videoseal.augmentation import Identity, H264, Crop\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos for trustmark_scaling0p5:   0%|          | 0/1 [00:00<?, ?it/s]/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/torchvision/io/video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading video /checkpoint/pfz/projects/videoseal/assets/videos/metamoviegen_3s/01.mp4 - took 1.38s\n",
      "embedding watermark  - took 1.83s\n",
      "PSNR: 48.485\n",
      "saving videos - took 10.20s\n",
      "compressing and detecting watermarks\n",
      "CRF=-1 - Bit Accuracy: 1.000 - P-Value: 7.89e-31 - Capacity: 100.000 - took 1.54s\n",
      "CRF=60 - Bit Accuracy: 0.480 - P-Value: 6.91e-01 - Capacity: 0.115 - took 1.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos for trustmark_scaling0p5: 100%|██████████| 1/1 [00:31<00:00, 31.91s/it]\n"
     ]
    }
   ],
   "source": [
    "from videoseal.models.baselines import build_baseline\n",
    "\n",
    "# Directory containing videos\n",
    "# video_dir = \"/checkpoint/pfz/projects/videoseal/assets/videos/metamoviegen/\"\n",
    "video_dir = \"/checkpoint/pfz/projects/videoseal/assets/videos/metamoviegen_3s/\"\n",
    "save_dir = \"outputs/\"\n",
    "# video_dir = \"/Users/pfz/Code/videoseal/assets/videos\"\n",
    "# save_dir = \"outputs\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "num_vids = 1\n",
    "fps = 24 // 1\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "# frames_per_clip = fps * 3  # 3s\n",
    "# frame_step = 1\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "\n",
    "# for method in [\"cin\", \"hidden\", \"mbrs\", \"wam\"]:\n",
    "for method in [\"trustmark_scaling0p5\"]:\n",
    "    wam = build_baseline(\n",
    "        method,  \n",
    "        step_size=8,\n",
    "        chunk_size=32\n",
    "    )\n",
    "    wam.eval()\n",
    "    wam.embedder.to(device)\n",
    "    wam.detector.to(device)\n",
    "\n",
    "    # Iterate over all video files in the directory\n",
    "    video_files = [f for f in os.listdir(video_dir) if f.endswith(\".mp4\")][:num_vids]\n",
    "    # video_files = [\"metamoviegen_3s.mp4\"]\n",
    "\n",
    "    for video_file in tqdm(video_files, desc=f\"Processing Videos for {method}\"):\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        base_name = os.path.splitext(video_file)[0]\n",
    "\n",
    "        # Load video (assuming a function `load_video` exists)\n",
    "        timer.start()\n",
    "        video_tensor, audio_tensor, info = torchvision.io.read_video(video_path)\n",
    "        vid = video_tensor.permute(0, 3, 1, 2).float() / 255.0\n",
    "        print(f\"loading video {video_path} - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Watermark embedding\n",
    "        timer.start()\n",
    "        outputs = wam.embed(vid, is_video=True)\n",
    "        print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # compute diff\n",
    "        imgs = vid  # b c h w\n",
    "        imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "        msgs = outputs[\"msgs\"]  # b k\n",
    "        diff = imgs_w - imgs\n",
    "\n",
    "        # psnr\n",
    "        psnr_score = psnr(imgs, imgs_w).mean().item()\n",
    "        print(f\"PSNR: {psnr_score:.3f}\")\n",
    "\n",
    "        # save\n",
    "        timer.start()\n",
    "        save_vid(imgs, f\"{save_dir}/{method}_{base_name}_ori.mp4\", fps)\n",
    "        save_vid(imgs_w, f\"{save_dir}/{method}_{base_name}_wm.mp4\", fps)\n",
    "        save_vid(10*diff.abs(), f\"{save_dir}/{method}_{base_name}_diff.mp4\", fps)\n",
    "\n",
    "        # Compute min and max values, reshape, and normalize\n",
    "        min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "        # Save the normalized video\n",
    "        save_vid(normalized_images, f\"{save_dir}/{method}_{base_name}_diff_normalized.mp4\", fps)\n",
    "        print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Augment video\n",
    "        print(f\"compressing and detecting watermarks\")\n",
    "        for crf in [-1, 60]:\n",
    "            if crf == -1:\n",
    "                imgs_aug = imgs_w\n",
    "            else:\n",
    "                imgs_aug, _ = H264()(imgs_w, crf=crf)\n",
    "\n",
    "            save_vid(imgs_aug, f\"{save_dir}/{method}_{base_name}_wm_crf{crf}.mp4\", fps)\n",
    "            # detect\n",
    "            timer.start()\n",
    "            # outputs = wam.detect(imgs_aug, is_video=True)\n",
    "            # preds = outputs[\"preds\"]\n",
    "            # bit_preds = preds[:, 1:]  # b k ...\n",
    "            # bit_accuracy_ = bit_accuracy(\n",
    "            #     bit_preds,\n",
    "            #     msgs\n",
    "            # ).nanmean().item()\n",
    "            bit_preds = wam.detect_and_aggregate(imgs_aug)\n",
    "            bit_accuracy_ = bit_accuracy(\n",
    "                bit_preds,\n",
    "                msgs[:1]\n",
    "            ).nanmean().item()\n",
    "            pvalue_ = pvalue(\n",
    "                bit_preds,\n",
    "                msgs[:1]\n",
    "            ).nanmean().item()\n",
    "            capacity_ = capacity(\n",
    "                bit_preds,\n",
    "                msgs[:1]\n",
    "            ).nanmean().item()\n",
    "            print(f\"CRF={crf} - Bit Accuracy: {bit_accuracy_:.3f} - P-Value: {pvalue_:0.2e} - Capacity: {capacity_:.3f} - took {timer.stop():.2f}s\")\n",
    "\n",
    "        del vid, outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "    # Free model from GPU\n",
    "    del wam\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoseal.models.baselines import build_baseline\n",
    "\n",
    "# Directory containing videos\n",
    "video_dir = \"/checkpoint/pfz/projects/videoseal/assets/videos/metamoviegen/\"\n",
    "save_dir = \"outputs/\"\n",
    "num_vids = 1\n",
    "fps = 24 // 1\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "# frames_per_clip = fps * 3  # 3s\n",
    "# frame_step = 1\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "\n",
    "# Iterate over all checkpoints\n",
    "interpolations = [\n",
    "    # {\"mode\": \"bilinear\", \"align_corners\": False, \"antialias\": False},\n",
    "    {\"mode\": \"bilinear\", \"align_corners\": False, \"antialias\": True},\n",
    "    # {\"mode\": \"bicubic\", \"align_corners\": False, \"antialias\": False},\n",
    "    # {\"mode\": \"bicubic\", \"align_corners\": False, \"antialias\": True},\n",
    "    # {\"mode\": \"bilinear\", \"align_corners\": True, \"antialias\": False},\n",
    "    # {\"mode\": \"bilinear\", \"align_corners\": True, \"antialias\": True},\n",
    "    # {\"mode\": \"bicubic\", \"align_corners\": True, \"antialias\": False},\n",
    "    # {\"mode\": \"bicubic\", \"align_corners\": True, \"antialias\": True},\n",
    "]\n",
    "for interpolation in interpolations:\n",
    "    print(f\"Interpolation: {interpolation}\")\n",
    "    for method in [\"cin\", \"hidden\", \"mbrs\"]:\n",
    "        wam = build_baseline(method)\n",
    "        wam.eval()\n",
    "\n",
    "        # Iterate over all video files in the directory\n",
    "        video_files = [f for f in os.listdir(video_dir) if f.endswith(\".mp4\")][:num_vids]\n",
    "\n",
    "        for video_file in tqdm(video_files, desc=f\"Processing Videos for {method}\"):\n",
    "            video_path = os.path.join(video_dir, video_file)\n",
    "            base_name = os.path.splitext(video_file)[0]\n",
    "\n",
    "            # Load video (assuming a function `load_video` exists)\n",
    "            timer.start()\n",
    "            vid, mask = VideoDataset.load_full_video_decord(video_path)\n",
    "            print(f\"loading video {video_path} - took {timer.stop():.2f}s\")\n",
    "\n",
    "            # Watermark embedding\n",
    "            timer.start()\n",
    "            outputs = wam.embed(vid, is_video=True, interpolation=interpolation)\n",
    "            print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "            # compute diff\n",
    "            imgs = vid  # b c h w\n",
    "            imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "            msgs = outputs[\"msgs\"]  # b k\n",
    "            diff = imgs_w - imgs\n",
    "\n",
    "            # psnr\n",
    "            psnr_score = psnr(imgs, imgs_w).mean().item()\n",
    "            print(f\"PSNR: {psnr_score:.3f}\")\n",
    "\n",
    "            # save\n",
    "            timer.start()\n",
    "            save_vid(imgs, f\"{save_dir}/{method}_{base_name}_ori.mp4\", fps)\n",
    "            save_vid(imgs_w, f\"{save_dir}/{method}_{base_name}_wm.mp4\", fps)\n",
    "            save_vid(diff, f\"{save_dir}/{method}_{base_name}_diff.mp4\", fps)\n",
    "\n",
    "            # Compute min and max values, reshape, and normalize\n",
    "            min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "            max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "            normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "            # Save the normalized video\n",
    "            save_vid(normalized_images, f\"{save_dir}/{method}_{base_name}_diff_normalized.mp4\", fps)\n",
    "            print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "            # Augment video\n",
    "            print(f\"cropping and detecting watermarks\")\n",
    "            for crop in [0.8, 0.9, 0.98, 1.0]:\n",
    "                masks = torch.ones_like(imgs)\n",
    "                imgs_aug, _ = Crop()(imgs_w, masks, crop)\n",
    "\n",
    "                # detect\n",
    "                timer.start()\n",
    "                outputs = wam.detect(imgs_aug, is_video=True)\n",
    "                preds = outputs[\"preds\"]\n",
    "                bit_preds = preds[:, 1:]  # b k ...\n",
    "                bit_accuracy_ = bit_accuracy(\n",
    "                    bit_preds,\n",
    "                    msgs\n",
    "                ).nanmean().item()\n",
    "                print(f\"crop={crop} Bit Accuracy: {bit_accuracy_:.3f} - detection took {timer.stop():.2f}s\")\n",
    "\n",
    "            del vid, mask, outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "        # Free model from GPU\n",
    "        del wam\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
