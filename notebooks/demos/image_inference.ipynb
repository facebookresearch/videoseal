{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/09-videoseal/videoseal-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from videoseal.utils.display import save_img\n",
    "from videoseal.utils import Timer\n",
    "from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy, psnr, ssim\n",
    "from videoseal.augmentation import Identity, JPEG\n",
    "from videoseal.modules.jnd import JND, VarianceBasedJND\n",
    "\n",
    "import os\n",
    "import omegaconf\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /checkpoint/pfz/2025_logs/0225_vseal_ydisc_with_jnd/_balanced=False_scaling_w=1.0/checkpoint.pth with message: <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|█         | 1/10 [00:02<00:26,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/chao.png', 'bit_accuracy': 0.984375, 'psnr': 41.70159149169922, 'ssim': 0.9969250559806824, 'bit_accuracy_qf80': 0.984375, 'bit_accuracy_qf40': 0.984375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  20%|██        | 2/10 [00:03<00:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/corgi_avocado.png', 'bit_accuracy': 1.0, 'psnr': 48.45660400390625, 'ssim': 0.9939095377922058, 'bit_accuracy_qf80': 0.9765625, 'bit_accuracy_qf40': 0.875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  30%|███       | 3/10 [00:04<00:08,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/trex_bike.png', 'bit_accuracy': 1.0, 'psnr': 44.01919937133789, 'ssim': 0.9958104491233826, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.984375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  40%|████      | 4/10 [00:05<00:08,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/tahiti.png', 'bit_accuracy': 1.0, 'psnr': 46.423221588134766, 'ssim': 0.998142659664154, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  60%|██████    | 6/10 [00:06<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/tahiti_512.png', 'bit_accuracy': 1.0, 'psnr': 46.664825439453125, 'ssim': 0.9963272213935852, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.9921875}\n",
      "{'file': '/private/home/pfz/_images/tahiti_256.png', 'bit_accuracy': 1.0, 'psnr': 44.914634704589844, 'ssim': 0.9919957518577576, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.96875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|███████   | 7/10 [00:19<00:13,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/gauguin.jpg', 'bit_accuracy': 0.9921875, 'psnr': 46.22822952270508, 'ssim': 0.9993532299995422, 'bit_accuracy_qf80': 0.9921875, 'bit_accuracy_qf40': 0.9921875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  80%|████████  | 8/10 [00:21<00:07,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/gauguin.png', 'bit_accuracy': 0.9921875, 'psnr': 46.33487319946289, 'ssim': 0.9980586171150208, 'bit_accuracy_qf80': 0.9921875, 'bit_accuracy_qf40': 0.9921875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 10/10 [00:21<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/gauguin_512.png', 'bit_accuracy': 1.0, 'psnr': 46.481380462646484, 'ssim': 0.9963685870170593, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n",
      "{'file': '/private/home/pfz/_images/gauguin_256.png', 'bit_accuracy': 1.0, 'psnr': 44.43343734741211, 'ssim': 0.9911230206489563, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.96875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory containing videos\n",
    "num_imgs = 10\n",
    "# assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
    "# assets_dir = \"/large_experiments/omniseal/sa-1b/val\"\n",
    "assets_dir = \"/private/home/pfz/_images\"\n",
    "base_output_dir = \"outputs\"\n",
    "# base_output_dir = \"/checkpoint/pfz/2025_logs/0206_vseal_rgb_y_images_for_s/att\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# Checkpoint\n",
    "ckpts = {\n",
    "    # \"videoseal0.1\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.5_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=unet_small2/checkpoint.pth',\n",
    "    # \"videoseal0.2b\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-archsearch-4nodes/_attenuation=None_nbits=64_finetune_detector_start=800_embedder_model=unet_small2_quant/checkpoint.pth\",\n",
    "    # \"videoseal0.2a\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1109-videoseal0.2-discloss-fix-hing-sleepwake-4nodes/_scaling_w=0.5_lambda_i=0.5_disc_hinge_on_logits_fake=True_sleepwake=False_video_start=500/checkpoint.pth\",\n",
    "    # \"videoseal0.4\": \"/large_experiments/meres/hadyelsahar/2024_logs/1120-videoseal0.4/_scaling_w=0.5_sleepwake=False_videowam_step_size=4_extractor_model=sam_tiny/checkpoint.pth\",\n",
    "    # \"trustmark\": \"baseline/trustmark\",\n",
    "    # \"wam\": \"baseline/wam\",\n",
    "    # \"cin\": \"baseline/cin\",\n",
    "    # \"mbrs\": \"baseline/mbrs\",\n",
    "    # \"rgb\": \"/checkpoint/pfz/2025_logs/0206_vseal_rgb_y_64bits_lessdisc/_lambda_d=0.1_optimizer=AdamW,lr=1e-4_embedder_model=1/checkpoint.pth\",\n",
    "    # \"y\": \"/checkpoint/pfz/2025_logs/0207_vseal_y_64bits_scalingw_schedule/_scaling_w_schedule=0_scaling_w=0.1/checkpoint650.pth\",\n",
    "    # \"96b_y\": \"/checkpoint/pfz/2025_logs/0219_vseal_convnextextractor/_nbits=96_lambda_i=0.1_embedder_model=1/checkpoint600.pth\",\n",
    "    # \"96b_y_400\": \"/checkpoint/pfz/2025_logs/0219_vseal_convnextextractor/_nbits=96_lambda_i=0.1_embedder_model=1/checkpoint400.pth\",\n",
    "    # \"hs1\": \"/checkpoint/pfz/2025_logs/0226_vseal_ydisc_mult1/_scaling_w_schedule=1_scaling_w=1.0_attenuation=jnd_1_1_hidden_size_multiplier=1/checkpoint.pth\",\n",
    "    \"hs2\": \"/checkpoint/pfz/2025_logs/0225_vseal_ydisc_with_jnd/_balanced=False_scaling_w=1.0/checkpoint.pth\",\n",
    "}\n",
    "\n",
    "for ckpt_name, ckpt_path in ckpts.items():\n",
    "\n",
    "    output_dir = os.path.join(base_output_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # a timer to measure the time\n",
    "    timer = Timer()\n",
    "\n",
    "    # Iterate over all checkpoints\n",
    "    wam = setup_model_from_checkpoint(ckpt_path)\n",
    "    wam.eval()\n",
    "    wam.to(device)\n",
    "\n",
    "    # attenuation = VarianceBasedJND(\n",
    "    #     mode=\"variance\",\n",
    "    #     max_variance_value_for_clipping=300,\n",
    "    #     min_heatmap_value=0.1,\n",
    "    #     avg_pool_kernel_size=3\n",
    "    # )\n",
    "    # attenuation = JND(\n",
    "    #     in_channels=1,\n",
    "    #     out_channels=1,\n",
    "    # )\n",
    "    # wam.attenuation = attenuation\n",
    "    # wam.blender.scaling_w = 0.016\n",
    "    wam.blender.scaling_w = 0.2\n",
    "\n",
    "    # Iterate over all video files in the directory\n",
    "    files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\") or f.endswith(\".jpg\")]\n",
    "    files = [os.path.join(assets_dir, f) for f in files]\n",
    "    files = files[:num_imgs]\n",
    "\n",
    "    for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "        # load image\n",
    "        imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "        imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "        # Watermark embedding\n",
    "        timer.start()\n",
    "        outputs = wam.embed_lowres_attenuation(imgs, is_video=False)\n",
    "        torch.cuda.synchronize()\n",
    "        # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # compute diff\n",
    "        imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "        msgs = outputs[\"msgs\"]  # b k\n",
    "        diff = imgs_w - imgs\n",
    "\n",
    "        # save\n",
    "        timer.start()\n",
    "        base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "        # print(f\"saving videos to {base_save_name}\")\n",
    "        save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "        save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "        save_img(20*diff[0].abs(), f\"{base_save_name}_diff.png\")\n",
    "\n",
    "        # Compute min and max values, reshape, and normalize\n",
    "        min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "        # Save the normalized video\n",
    "        save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "        # print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Metrics\n",
    "        imgs_aug = imgs_w\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        metrics = {\n",
    "            \"file\": file,\n",
    "            \"bit_accuracy\": bit_accuracy(\n",
    "                outputs[\"preds\"][:, 1:],\n",
    "                msgs\n",
    "            ).nanmean().item(),\n",
    "            \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "            \"ssim\": ssim(imgs_w, imgs).item()\n",
    "        }\n",
    "\n",
    "        # Augment video\n",
    "        # print(f\"compressing and detecting watermarks\")\n",
    "        for qf in [80, 40]:\n",
    "            imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "            # detect\n",
    "            timer.start()\n",
    "            outputs = wam.detect(imgs_aug, is_video=True)\n",
    "            preds = outputs[\"preds\"]\n",
    "            # print(preds)\n",
    "            bit_preds = preds[:, 1:]  # b k ...\n",
    "            bit_accuracy_ = bit_accuracy(\n",
    "                bit_preds,\n",
    "                msgs\n",
    "            ).nanmean().item()\n",
    "            \n",
    "            metrics[f\"bit_accuracy_qf{qf}\"] = bit_accuracy_\n",
    "\n",
    "        print(metrics)\n",
    "\n",
    "        del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "    # Free model from GPU\n",
    "    del wam\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With attenuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing videos\n",
    "assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
    "output_dir = \"outputs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Checkpoint\n",
    "ckpt_path = \"videoseal\"\n",
    "# ckpt_path = \"/checkpoint/pfz/2025_logs/0115_vseal_rgb_96bits_nopercep_yuv/_scaling_w=0.05_lambda_d=0.5_extractor_model=sam_small/checkpoint.pth\"\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "\n",
    "# Iterate over all checkpoints\n",
    "wam = setup_model_from_checkpoint(ckpt_path)\n",
    "wam.eval()\n",
    "wam.to(device)\n",
    "\n",
    "# create attenuation\n",
    "attenuation = VarianceBasedJND(\n",
    "    mode=\"variance\",\n",
    "    max_variance_value_for_clipping=300,\n",
    "    min_heatmap_value=0.1,\n",
    "    avg_pool_kernel_size=3\n",
    ")\n",
    "wam.attenuation = attenuation\n",
    "wam.blender.scaling_w = 20.0\n",
    "\n",
    "# Iterate over all video files in the directory\n",
    "files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\")]\n",
    "files = [os.path.join(assets_dir, f) for f in files]\n",
    "\n",
    "for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "    # load image\n",
    "    imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "    imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "    # Watermark embedding\n",
    "    timer.start()\n",
    "    outputs = wam.embed(imgs, is_video=False)\n",
    "    # torch.cuda.synchronize()\n",
    "    # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "    # compute diff\n",
    "    imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "    msgs = outputs[\"msgs\"]  # b k\n",
    "    diff = imgs_w - imgs\n",
    "\n",
    "    # save\n",
    "    timer.start()\n",
    "    base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "    save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "    save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "    save_img(diff[0], f\"{base_save_name}_diff.png\")\n",
    "\n",
    "    # Compute min and max values, reshape, and normalize\n",
    "    min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "    # Save the normalized video\n",
    "    save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "\n",
    "    # Metrics\n",
    "    imgs_aug = imgs_w\n",
    "    outputs = wam.detect(imgs_aug, is_video=False)\n",
    "    metrics = {\n",
    "        \"bit_accuracy\": bit_accuracy(\n",
    "            outputs[\"preds\"][:, 1:],\n",
    "            msgs\n",
    "        ).nanmean().item(),\n",
    "        \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "        \"ssim\": ssim(imgs_w, imgs).item()\n",
    "    }\n",
    "\n",
    "    # Augment video\n",
    "    for qf in [80, 40]:\n",
    "        imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "        # detect\n",
    "        timer.start()\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        preds = outputs[\"preds\"]\n",
    "        bit_preds = preds[:, 1:]  # b k ...\n",
    "        bit_accuracy_ = bit_accuracy(\n",
    "            bit_preds,\n",
    "            msgs\n",
    "        ).nanmean().item()\n",
    "        metrics[f\"bit_accuracy_qf_{qf}\"] = bit_accuracy_\n",
    "    \n",
    "    print(metrics)\n",
    "    del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "# Free model from GPU\n",
    "del wam\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
