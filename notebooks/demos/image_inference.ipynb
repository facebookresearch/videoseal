{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/09-videoseal/videoseal-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from videoseal.utils.display import save_img\n",
    "from videoseal.utils import Timer\n",
    "from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy, psnr, ssim\n",
    "from videoseal.augmentation import Identity, JPEG\n",
    "from videoseal.modules.jnd import JND, VarianceBasedJND\n",
    "\n",
    "import os\n",
    "import omegaconf\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /checkpoint/pfz/2025_logs/0115_vseal_rgb_96bits_nopercep_yuv/_scaling_w=0.05_lambda_d=0.5_extractor_model=sam_small/checkpoint.pth with message: _IncompatibleKeys(missing_keys=['detector.pixel_decoder.linear.bias'], unexpected_keys=[])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  25%|██▌       | 1/4 [00:01<00:05,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 33.734886169433594, 'ssim': 0.975898027420044, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|█████     | 2/4 [00:02<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 34.71742630004883, 'ssim': 0.9345903396606445, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  75%|███████▌  | 3/4 [00:07<00:02,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 32.39744567871094, 'ssim': 0.9686586260795593, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 4/4 [00:07<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 33.420494079589844, 'ssim': 0.9584458470344543, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory containing videos\n",
    "assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
    "# assets_dir = \"/private/home/pfz/_images\"\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Checkpoint\n",
    "ckpts = {\n",
    "    # \"videoseal0.1\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.5_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=unet_small2/checkpoint.pth',\n",
    "    # \"videoseal0.2b\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-archsearch-4nodes/_attenuation=None_nbits=64_finetune_detector_start=800_embedder_model=unet_small2_quant/checkpoint.pth\",\n",
    "    # \"videoseal0.2a\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1109-videoseal0.2-discloss-fix-hing-sleepwake-4nodes/_scaling_w=0.5_lambda_i=0.5_disc_hinge_on_logits_fake=True_sleepwake=False_video_start=500/checkpoint.pth\",\n",
    "    # \"videoseal0.4\": \"/large_experiments/meres/hadyelsahar/2024_logs/1120-videoseal0.4/_scaling_w=0.5_sleepwake=False_videowam_step_size=4_extractor_model=sam_tiny/checkpoint.pth\",\n",
    "    # \"trustmark\": \"baseline/trustmark\",\n",
    "    # \"wam\": \"baseline/wam\",\n",
    "    # \"cin\": \"baseline/cin\",\n",
    "    # \"mbrs\": \"baseline/mbrs\",\n",
    "    \"ychannel\": \"/checkpoint/pfz/2025_logs/0115_vseal_rgb_96bits_nopercep_yuv/_scaling_w=0.05_lambda_d=0.5_extractor_model=sam_small/checkpoint.pth\",\n",
    "}\n",
    "\n",
    "for ckpt_name, ckpt_path in ckpts.items():\n",
    "\n",
    "    # a timer to measure the time\n",
    "    timer = Timer()\n",
    "\n",
    "    # Iterate over all checkpoints\n",
    "    wam = setup_model_from_checkpoint(ckpt_path)\n",
    "    wam.eval()\n",
    "    wam.to(device)\n",
    "\n",
    "    # Iterate over all video files in the directory\n",
    "    files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\")]\n",
    "    files = [os.path.join(assets_dir, f) for f in files]\n",
    "\n",
    "    for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "        # load image\n",
    "        imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "        imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "        # Watermark embedding\n",
    "        timer.start()\n",
    "        outputs = wam.embed(imgs, is_video=False)\n",
    "        torch.cuda.synchronize()\n",
    "        # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # compute diff\n",
    "        imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "        msgs = outputs[\"msgs\"]  # b k\n",
    "        diff = imgs_w - imgs\n",
    "\n",
    "        # save\n",
    "        timer.start()\n",
    "        base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "        # print(f\"saving videos to {base_save_name}\")\n",
    "        save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "        save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "        save_img(20*diff[0].abs(), f\"{base_save_name}_diff.png\")\n",
    "\n",
    "        # Compute min and max values, reshape, and normalize\n",
    "        min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "        # Save the normalized video\n",
    "        save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "        # print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Metrics\n",
    "        imgs_aug = imgs_w\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        metrics = {\n",
    "            \"bit_accuracy\": bit_accuracy(\n",
    "                outputs[\"preds\"][:, 1:],\n",
    "                msgs\n",
    "            ).nanmean().item(),\n",
    "            \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "            \"ssim\": ssim(imgs_w, imgs).item()\n",
    "        }\n",
    "\n",
    "        # Augment video\n",
    "        # print(f\"compressing and detecting watermarks\")\n",
    "        for qf in [80, 40]:\n",
    "            imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "            # detect\n",
    "            timer.start()\n",
    "            outputs = wam.detect(imgs_aug, is_video=True)\n",
    "            preds = outputs[\"preds\"]\n",
    "            # print(preds)\n",
    "            bit_preds = preds[:, 1:]  # b k ...\n",
    "            bit_accuracy_ = bit_accuracy(\n",
    "                bit_preds,\n",
    "                msgs\n",
    "            ).nanmean().item()\n",
    "            \n",
    "            metrics[f\"bit_accuracy_qf{qf}\"] = bit_accuracy_\n",
    "\n",
    "        print(metrics)\n",
    "\n",
    "        del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "    # Free model from GPU\n",
    "    del wam\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With attenuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /private/home/pfz/.cache/huggingface/hub/models--facebook--video_seal/snapshots/8037ef59ba2b2ec8fb8b55298ff37b8ccddd078d/checkpoint.pth with message: <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.9166666865348816, 'psnr': 46.27751541137695, 'ssim': 0.9988591074943542, 'bit_accuracy_qf_80': 0.9270833134651184, 'bit_accuracy_qf_40': 0.8854166865348816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|█████     | 2/4 [00:01<00:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.9895833134651184, 'psnr': 49.10234069824219, 'ssim': 0.9982087016105652, 'bit_accuracy_qf_80': 0.9895833134651184, 'bit_accuracy_qf_40': 0.7395833134651184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  75%|███████▌  | 3/4 [00:06<00:02,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.9895833134651184, 'psnr': 45.21706008911133, 'ssim': 0.9980943202972412, 'bit_accuracy_qf_80': 0.9791666865348816, 'bit_accuracy_qf_40': 0.9895833134651184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 4/4 [00:06<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 46.6027717590332, 'ssim': 0.998041570186615, 'bit_accuracy_qf_80': 0.9895833134651184, 'bit_accuracy_qf_40': 0.96875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory containing videos\n",
    "assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
    "output_dir = \"outputs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Checkpoint\n",
    "ckpt_path = \"videoseal\"\n",
    "# ckpt_path = \"/checkpoint/pfz/2025_logs/0115_vseal_rgb_96bits_nopercep_yuv/_scaling_w=0.05_lambda_d=0.5_extractor_model=sam_small/checkpoint.pth\"\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "\n",
    "# Iterate over all checkpoints\n",
    "wam = setup_model_from_checkpoint(ckpt_path)\n",
    "wam.eval()\n",
    "wam.to(device)\n",
    "\n",
    "# create attenuation\n",
    "attenuation = VarianceBasedJND(\n",
    "    mode=\"variance\",\n",
    "    max_variance_value_for_clipping=300,\n",
    "    min_heatmap_value=0.1,\n",
    "    avg_pool_kernel_size=3\n",
    ")\n",
    "wam.attenuation = attenuation\n",
    "wam.blender.scaling_w = 20.0\n",
    "\n",
    "# Iterate over all video files in the directory\n",
    "files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\")]\n",
    "files = [os.path.join(assets_dir, f) for f in files]\n",
    "\n",
    "for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "    # load image\n",
    "    imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "    imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "    # Watermark embedding\n",
    "    timer.start()\n",
    "    outputs = wam.embed(imgs, is_video=False)\n",
    "    # torch.cuda.synchronize()\n",
    "    # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "    # compute diff\n",
    "    imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "    msgs = outputs[\"msgs\"]  # b k\n",
    "    diff = imgs_w - imgs\n",
    "\n",
    "    # save\n",
    "    timer.start()\n",
    "    base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "    save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "    save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "    save_img(diff[0], f\"{base_save_name}_diff.png\")\n",
    "\n",
    "    # Compute min and max values, reshape, and normalize\n",
    "    min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "    # Save the normalized video\n",
    "    save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "\n",
    "    # Metrics\n",
    "    imgs_aug = imgs_w\n",
    "    outputs = wam.detect(imgs_aug, is_video=False)\n",
    "    metrics = {\n",
    "        \"bit_accuracy\": bit_accuracy(\n",
    "            outputs[\"preds\"][:, 1:],\n",
    "            msgs\n",
    "        ).nanmean().item(),\n",
    "        \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "        \"ssim\": ssim(imgs_w, imgs).item()\n",
    "    }\n",
    "\n",
    "    # Augment video\n",
    "    for qf in [80, 40]:\n",
    "        imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "        # detect\n",
    "        timer.start()\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        preds = outputs[\"preds\"]\n",
    "        bit_preds = preds[:, 1:]  # b k ...\n",
    "        bit_accuracy_ = bit_accuracy(\n",
    "            bit_preds,\n",
    "            msgs\n",
    "        ).nanmean().item()\n",
    "        metrics[f\"bit_accuracy_qf_{qf}\"] = bit_accuracy_\n",
    "    \n",
    "    print(metrics)\n",
    "    del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "# Free model from GPU\n",
    "del wam\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
