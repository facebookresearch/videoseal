{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/09-videoseal/videoseal-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from videoseal.utils.display import save_img\n",
    "from videoseal.utils import Timer\n",
    "from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy, psnr, ssim\n",
    "from videoseal.augmentation import Identity, JPEG\n",
    "from videoseal.modules.jnd import JND, VarianceBasedJND\n",
    "\n",
    "import os\n",
    "import omegaconf\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /checkpoint/pfz/2025_logs/0219_vseal_convnextextractor/_nbits=96_lambda_i=0.1_embedder_model=1/checkpoint600.pth with message: <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|█         | 1/10 [00:03<00:33,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 39.8629264831543, 'ssim': 0.9945476651191711, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  20%|██        | 2/10 [00:07<00:30,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 40.429771423339844, 'ssim': 0.9964190125465393, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  30%|███       | 3/10 [00:12<00:29,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 39.848846435546875, 'ssim': 0.9975709915161133, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  40%|████      | 4/10 [00:16<00:25,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 39.64069747924805, 'ssim': 0.996229887008667, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|█████     | 5/10 [00:20<00:21,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 40.11200714111328, 'ssim': 0.9972754120826721, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  60%|██████    | 6/10 [00:25<00:17,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 39.58835983276367, 'ssim': 0.9928290843963623, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|███████   | 7/10 [00:29<00:12,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 42.56237030029297, 'ssim': 0.9980538487434387, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  80%|████████  | 8/10 [00:32<00:07,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 40.15971374511719, 'ssim': 0.9958235621452332, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  90%|█████████ | 9/10 [00:37<00:04,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 40.461456298828125, 'ssim': 0.9953904151916504, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 10/10 [00:40<00:00,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 39.8139762878418, 'ssim': 0.9935389161109924, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /checkpoint/pfz/2025_logs/0219_vseal_convnextextractor/_nbits=96_lambda_i=0.1_embedder_model=1/checkpoint400.pth with message: <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  10%|█         | 1/10 [00:03<00:30,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.5208333134651184, 'psnr': 46.75999450683594, 'ssim': 0.9991652369499207, 'bit_accuracy_qf80': 0.5104166865348816, 'bit_accuracy_qf40': 0.53125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  20%|██        | 2/10 [00:06<00:28,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.6875, 'psnr': 47.262420654296875, 'ssim': 0.9994601607322693, 'bit_accuracy_qf80': 0.7708333134651184, 'bit_accuracy_qf40': 0.6979166865348816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  30%|███       | 3/10 [00:11<00:27,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.4479166567325592, 'psnr': 45.9100227355957, 'ssim': 0.9995020031929016, 'bit_accuracy_qf80': 0.4375, 'bit_accuracy_qf40': 0.4270833432674408}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  40%|████      | 4/10 [00:15<00:23,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.5208333134651184, 'psnr': 46.37257766723633, 'ssim': 0.9990463852882385, 'bit_accuracy_qf80': 0.53125, 'bit_accuracy_qf40': 0.5104166865348816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|█████     | 5/10 [00:19<00:19,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.53125, 'psnr': 45.80270004272461, 'ssim': 0.999504566192627, 'bit_accuracy_qf80': 0.4479166567325592, 'bit_accuracy_qf40': 0.5208333134651184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  60%|██████    | 6/10 [00:23<00:15,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.5, 'psnr': 45.30924606323242, 'ssim': 0.9989807605743408, 'bit_accuracy_qf80': 0.5104166865348816, 'bit_accuracy_qf40': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|███████   | 7/10 [00:27<00:11,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.7916666865348816, 'psnr': 46.6107063293457, 'ssim': 0.9994402527809143, 'bit_accuracy_qf80': 0.8125, 'bit_accuracy_qf40': 0.6666666865348816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  80%|████████  | 8/10 [00:30<00:07,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.5625, 'psnr': 45.93770980834961, 'ssim': 0.9991415143013, 'bit_accuracy_qf80': 0.5833333134651184, 'bit_accuracy_qf40': 0.625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  90%|█████████ | 9/10 [00:34<00:03,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.5416666865348816, 'psnr': 48.0381965637207, 'ssim': 0.9993906617164612, 'bit_accuracy_qf80': 0.5416666865348816, 'bit_accuracy_qf40': 0.5520833134651184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 10/10 [00:38<00:00,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.65625, 'psnr': 44.63625717163086, 'ssim': 0.9983169436454773, 'bit_accuracy_qf80': 0.6979166865348816, 'bit_accuracy_qf40': 0.6041666865348816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory containing videos\n",
    "num_imgs = 10\n",
    "assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
    "assets_dir = \"/large_experiments/omniseal/sa-1b/val\"\n",
    "# assets_dir = \"/private/home/pfz/_images\"\n",
    "base_output_dir = \"outputs\"\n",
    "# base_output_dir = \"/checkpoint/pfz/2025_logs/0206_vseal_rgb_y_images_for_s/att\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# Checkpoint\n",
    "ckpts = {\n",
    "    # \"videoseal0.1\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.5_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=unet_small2/checkpoint.pth',\n",
    "    # \"videoseal0.2b\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-archsearch-4nodes/_attenuation=None_nbits=64_finetune_detector_start=800_embedder_model=unet_small2_quant/checkpoint.pth\",\n",
    "    # \"videoseal0.2a\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1109-videoseal0.2-discloss-fix-hing-sleepwake-4nodes/_scaling_w=0.5_lambda_i=0.5_disc_hinge_on_logits_fake=True_sleepwake=False_video_start=500/checkpoint.pth\",\n",
    "    # \"videoseal0.4\": \"/large_experiments/meres/hadyelsahar/2024_logs/1120-videoseal0.4/_scaling_w=0.5_sleepwake=False_videowam_step_size=4_extractor_model=sam_tiny/checkpoint.pth\",\n",
    "    # \"trustmark\": \"baseline/trustmark\",\n",
    "    # \"wam\": \"baseline/wam\",\n",
    "    # \"cin\": \"baseline/cin\",\n",
    "    # \"mbrs\": \"baseline/mbrs\",\n",
    "    # \"rgb\": \"/checkpoint/pfz/2025_logs/0206_vseal_rgb_y_64bits_lessdisc/_lambda_d=0.1_optimizer=AdamW,lr=1e-4_embedder_model=1/checkpoint.pth\",\n",
    "    # \"y\": \"/checkpoint/pfz/2025_logs/0207_vseal_y_64bits_scalingw_schedule/_scaling_w_schedule=0_scaling_w=0.1/checkpoint650.pth\",\n",
    "    \"96b_y\": \"/checkpoint/pfz/2025_logs/0219_vseal_convnextextractor/_nbits=96_lambda_i=0.1_embedder_model=1/checkpoint600.pth\",\n",
    "    \"96b_y_400\": \"/checkpoint/pfz/2025_logs/0219_vseal_convnextextractor/_nbits=96_lambda_i=0.1_embedder_model=1/checkpoint400.pth\",\n",
    "}\n",
    "\n",
    "for ckpt_name, ckpt_path in ckpts.items():\n",
    "\n",
    "    output_dir = os.path.join(base_output_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # a timer to measure the time\n",
    "    timer = Timer()\n",
    "\n",
    "    # Iterate over all checkpoints\n",
    "    wam = setup_model_from_checkpoint(ckpt_path)\n",
    "    wam.eval()\n",
    "    wam.to(device)\n",
    "\n",
    "    # attenuation = VarianceBasedJND(\n",
    "    #     mode=\"variance\",\n",
    "    #     max_variance_value_for_clipping=300,\n",
    "    #     min_heatmap_value=0.1,\n",
    "    #     avg_pool_kernel_size=3\n",
    "    # )\n",
    "    # attenuation = JND(\n",
    "    #     in_channels=1,\n",
    "    #     out_channels=1,\n",
    "    # )\n",
    "    # wam.attenuation = attenuation\n",
    "    wam.blender.scaling_w = 0.016\n",
    "\n",
    "    # Iterate over all video files in the directory\n",
    "    files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\") or f.endswith(\".jpg\")]\n",
    "    files = [os.path.join(assets_dir, f) for f in files]\n",
    "    files = files[:num_imgs]\n",
    "\n",
    "    for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "        # load image\n",
    "        imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "        imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "        # Watermark embedding\n",
    "        timer.start()\n",
    "        outputs = wam.embed(imgs, is_video=False)\n",
    "        torch.cuda.synchronize()\n",
    "        # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # compute diff\n",
    "        imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "        msgs = outputs[\"msgs\"]  # b k\n",
    "        diff = imgs_w - imgs\n",
    "\n",
    "        # save\n",
    "        timer.start()\n",
    "        base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "        # print(f\"saving videos to {base_save_name}\")\n",
    "        save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "        save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "        save_img(20*diff[0].abs(), f\"{base_save_name}_diff.png\")\n",
    "\n",
    "        # Compute min and max values, reshape, and normalize\n",
    "        min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "        # Save the normalized video\n",
    "        save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "        # print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Metrics\n",
    "        imgs_aug = imgs_w\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        metrics = {\n",
    "            \"bit_accuracy\": bit_accuracy(\n",
    "                outputs[\"preds\"][:, 1:],\n",
    "                msgs\n",
    "            ).nanmean().item(),\n",
    "            \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "            \"ssim\": ssim(imgs_w, imgs).item()\n",
    "        }\n",
    "\n",
    "        # Augment video\n",
    "        # print(f\"compressing and detecting watermarks\")\n",
    "        for qf in [80, 40]:\n",
    "            imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "            # detect\n",
    "            timer.start()\n",
    "            outputs = wam.detect(imgs_aug, is_video=True)\n",
    "            preds = outputs[\"preds\"]\n",
    "            # print(preds)\n",
    "            bit_preds = preds[:, 1:]  # b k ...\n",
    "            bit_accuracy_ = bit_accuracy(\n",
    "                bit_preds,\n",
    "                msgs\n",
    "            ).nanmean().item()\n",
    "            \n",
    "            metrics[f\"bit_accuracy_qf{qf}\"] = bit_accuracy_\n",
    "\n",
    "        print(metrics)\n",
    "\n",
    "        del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "    # Free model from GPU\n",
    "    del wam\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With attenuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing videos\n",
    "assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
    "output_dir = \"outputs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Checkpoint\n",
    "ckpt_path = \"videoseal\"\n",
    "# ckpt_path = \"/checkpoint/pfz/2025_logs/0115_vseal_rgb_96bits_nopercep_yuv/_scaling_w=0.05_lambda_d=0.5_extractor_model=sam_small/checkpoint.pth\"\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "\n",
    "# Iterate over all checkpoints\n",
    "wam = setup_model_from_checkpoint(ckpt_path)\n",
    "wam.eval()\n",
    "wam.to(device)\n",
    "\n",
    "# create attenuation\n",
    "attenuation = VarianceBasedJND(\n",
    "    mode=\"variance\",\n",
    "    max_variance_value_for_clipping=300,\n",
    "    min_heatmap_value=0.1,\n",
    "    avg_pool_kernel_size=3\n",
    ")\n",
    "wam.attenuation = attenuation\n",
    "wam.blender.scaling_w = 20.0\n",
    "\n",
    "# Iterate over all video files in the directory\n",
    "files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\")]\n",
    "files = [os.path.join(assets_dir, f) for f in files]\n",
    "\n",
    "for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "    # load image\n",
    "    imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "    imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "    # Watermark embedding\n",
    "    timer.start()\n",
    "    outputs = wam.embed(imgs, is_video=False)\n",
    "    # torch.cuda.synchronize()\n",
    "    # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "    # compute diff\n",
    "    imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "    msgs = outputs[\"msgs\"]  # b k\n",
    "    diff = imgs_w - imgs\n",
    "\n",
    "    # save\n",
    "    timer.start()\n",
    "    base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "    save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "    save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "    save_img(diff[0], f\"{base_save_name}_diff.png\")\n",
    "\n",
    "    # Compute min and max values, reshape, and normalize\n",
    "    min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "    # Save the normalized video\n",
    "    save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "\n",
    "    # Metrics\n",
    "    imgs_aug = imgs_w\n",
    "    outputs = wam.detect(imgs_aug, is_video=False)\n",
    "    metrics = {\n",
    "        \"bit_accuracy\": bit_accuracy(\n",
    "            outputs[\"preds\"][:, 1:],\n",
    "            msgs\n",
    "        ).nanmean().item(),\n",
    "        \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "        \"ssim\": ssim(imgs_w, imgs).item()\n",
    "    }\n",
    "\n",
    "    # Augment video\n",
    "    for qf in [80, 40]:\n",
    "        imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "        # detect\n",
    "        timer.start()\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        preds = outputs[\"preds\"]\n",
    "        bit_preds = preds[:, 1:]  # b k ...\n",
    "        bit_accuracy_ = bit_accuracy(\n",
    "            bit_preds,\n",
    "            msgs\n",
    "        ).nanmean().item()\n",
    "        metrics[f\"bit_accuracy_qf_{qf}\"] = bit_accuracy_\n",
    "    \n",
    "    print(metrics)\n",
    "    del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "# Free model from GPU\n",
    "del wam\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
