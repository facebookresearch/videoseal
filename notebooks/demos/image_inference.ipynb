{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution inference "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 2,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/checkpoint/pfz/2025_logs/0119_vseal_rgb_96bits_nopercep_yuv_ftjnd/code\n"
=======
      "/private/home/pfz/09-videoseal/videoseal-dev\n"
>>>>>>> main
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 3,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoseal.utils.display import save_img\n",
    "from videoseal.utils import Timer\n",
    "from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy, psnr, ssim\n",
    "from videoseal.augmentation import Identity, JPEG\n",
    "from videoseal.modules.jnd import JND, VarianceBasedJND\n",
    "\n",
    "import os\n",
    "import omegaconf\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 3,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of videoseal.utils.cfg failed: Traceback (most recent call last):\n",
      "  File \"/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/private/home/pfz/miniconda3/envs/img/lib/python3.12/importlib/__init__.py\", line 131, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 866, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"/checkpoint/pfz/2025_logs/0119_vseal_rgb_96bits_nopercep_yuv_ftjnd/code/videoseal/utils/cfg.py\", line 23, in <module>\n",
      "    omegaconf.OmegaConf.register_new_resolver(\"mul\", lambda x, y: x * y)\n",
      "  File \"/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/omegaconf/omegaconf.py\", line 403, in register_new_resolver\n",
      "    raise ValueError(f\"resolver '{name}' is already registered\")\n",
      "ValueError: resolver 'mul' is already registered\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Model loaded successfully from /checkpoint/pfz/2025_logs/0119_vseal_rgb_96bits_nopercep_yuv_ftjnd/_scaling_w=0.1_resume_from=3/checkpoint.pth with message: <All keys matched successfully>\n"
=======
      "Model loaded successfully from /checkpoint/pfz/2025_logs/0115_vseal_rgb_96bits_nopercep_yuv/_scaling_w=0.05_lambda_d=0.5_extractor_model=sam_small/checkpoint.pth with message: _IncompatibleKeys(missing_keys=['detector.pixel_decoder.linear.bias'], unexpected_keys=[])\n"
>>>>>>> main
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Processing Images:  25%|██▌       | 1/4 [00:01<00:05,  1.75s/it]"
=======
      "Processing Images:  25%|██▌       | 1/4 [00:01<00:05,  1.80s/it]"
>>>>>>> main
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'bit_accuracy': 1.0, 'psnr': 39.74147033691406, 'ssim': 0.9939220547676086, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
=======
      "{'bit_accuracy': 1.0, 'psnr': 33.734886169433594, 'ssim': 0.975898027420044, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
>>>>>>> main
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Processing Images:  50%|█████     | 2/4 [00:02<00:01,  1.07it/s]"
=======
      "Processing Images:  50%|█████     | 2/4 [00:02<00:01,  1.03it/s]"
>>>>>>> main
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'bit_accuracy': 1.0, 'psnr': 42.06798553466797, 'ssim': 0.981702983379364, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
=======
      "{'bit_accuracy': 1.0, 'psnr': 34.71742630004883, 'ssim': 0.9345903396606445, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
>>>>>>> main
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Processing Images:  75%|███████▌  | 3/4 [00:07<00:02,  2.75s/it]"
=======
      "Processing Images:  75%|███████▌  | 3/4 [00:07<00:02,  2.77s/it]"
>>>>>>> main
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'bit_accuracy': 0.96875, 'psnr': 43.82460021972656, 'ssim': 0.9969899654388428, 'bit_accuracy_qf80': 0.9583333134651184, 'bit_accuracy_qf40': 0.9791666865348816}\n"
=======
      "{'bit_accuracy': 1.0, 'psnr': 32.39744567871094, 'ssim': 0.9686586260795593, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
>>>>>>> main
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Processing Images: 100%|██████████| 4/4 [00:07<00:00,  1.90s/it]"
=======
      "Processing Images: 100%|██████████| 4/4 [00:07<00:00,  1.93s/it]"
>>>>>>> main
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'bit_accuracy': 0.9895833134651184, 'psnr': 35.41111373901367, 'ssim': 0.9852557182312012, 'bit_accuracy_qf80': 0.9895833134651184, 'bit_accuracy_qf40': 1.0}\n"
=======
      "{'bit_accuracy': 1.0, 'psnr': 33.420494079589844, 'ssim': 0.9584458470344543, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 1.0}\n"
>>>>>>> main
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory containing videos\n",
    "num_imgs = 5\n",
    "assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
<<<<<<< HEAD
=======
    "# assets_dir = \"/private/home/pfz/_images\"\n",
>>>>>>> main
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Checkpoint\n",
    "ckpts = {\n",
<<<<<<< HEAD
=======
    "    # \"videoseal0.1\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.5_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=unet_small2/checkpoint.pth',\n",
    "    # \"videoseal0.2b\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-archsearch-4nodes/_attenuation=None_nbits=64_finetune_detector_start=800_embedder_model=unet_small2_quant/checkpoint.pth\",\n",
    "    # \"videoseal0.2a\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1109-videoseal0.2-discloss-fix-hing-sleepwake-4nodes/_scaling_w=0.5_lambda_i=0.5_disc_hinge_on_logits_fake=True_sleepwake=False_video_start=500/checkpoint.pth\",\n",
    "    # \"videoseal0.4\": \"/large_experiments/meres/hadyelsahar/2024_logs/1120-videoseal0.4/_scaling_w=0.5_sleepwake=False_videowam_step_size=4_extractor_model=sam_tiny/checkpoint.pth\",\n",
>>>>>>> main
    "    # \"trustmark\": \"baseline/trustmark\",\n",
    "    # \"wam\": \"baseline/wam\",\n",
    "    # \"cin\": \"baseline/cin\",\n",
    "    # \"mbrs\": \"baseline/mbrs\",\n",
<<<<<<< HEAD
    "    \"_scaling_w=0.1_resume_from=3\": '/checkpoint/pfz/2025_logs/0119_vseal_rgb_96bits_nopercep_yuv_ftjnd/_scaling_w=0.1_resume_from=3/checkpoint.pth',\n",
=======
    "    \"ychannel\": \"/checkpoint/pfz/2025_logs/0115_vseal_rgb_96bits_nopercep_yuv/_scaling_w=0.05_lambda_d=0.5_extractor_model=sam_small/checkpoint.pth\",\n",
>>>>>>> main
    "}\n",
    "\n",
    "for ckpt_name, ckpt_path in ckpts.items():\n",
    "\n",
    "    # a timer to measure the time\n",
    "    timer = Timer()\n",
    "\n",
    "    # Iterate over all checkpoints\n",
    "    wam = setup_model_from_checkpoint(ckpt_path)\n",
    "    wam.eval()\n",
    "    wam.to(device)\n",
    "\n",
    "    # Iterate over all video files in the directory\n",
    "    files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\")]\n",
    "    files = [os.path.join(assets_dir, f) for f in files]\n",
    "    files = files[:num_imgs]\n",
    "\n",
    "    for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "        # load image\n",
    "        imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "        imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "        # Watermark embedding\n",
    "        timer.start()\n",
    "        outputs = wam.embed(imgs, is_video=False)\n",
    "        torch.cuda.synchronize()\n",
    "        # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # compute diff\n",
    "        imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "        msgs = outputs[\"msgs\"]  # b k\n",
    "        diff = imgs_w - imgs\n",
    "\n",
    "        # save\n",
    "        timer.start()\n",
    "        base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "        # print(f\"saving videos to {base_save_name}\")\n",
    "        save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "        save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "        save_img(20*diff[0].abs(), f\"{base_save_name}_diff.png\")\n",
    "\n",
    "        # Compute min and max values, reshape, and normalize\n",
    "        min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "        # Save the normalized video\n",
    "        save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "        # print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Metrics\n",
    "        imgs_aug = imgs_w\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        metrics = {\n",
    "            \"bit_accuracy\": bit_accuracy(\n",
    "                outputs[\"preds\"][:, 1:],\n",
    "                msgs\n",
    "            ).nanmean().item(),\n",
    "            \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "            \"ssim\": ssim(imgs_w, imgs).item()\n",
    "        }\n",
    "\n",
    "        # Augment video\n",
    "        # print(f\"compressing and detecting watermarks\")\n",
    "        for qf in [80, 40]:\n",
    "            imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "            # detect\n",
    "            timer.start()\n",
    "            outputs = wam.detect(imgs_aug, is_video=True)\n",
    "            preds = outputs[\"preds\"]\n",
    "            # print(preds)\n",
    "            bit_preds = preds[:, 1:]  # b k ...\n",
    "            bit_accuracy_ = bit_accuracy(\n",
    "                bit_preds,\n",
    "                msgs\n",
    "            ).nanmean().item()\n",
    "            \n",
    "            metrics[f\"bit_accuracy_qf{qf}\"] = bit_accuracy_\n",
    "\n",
    "        print(metrics)\n",
    "\n",
    "        del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "    # Free model from GPU\n",
    "    del wam\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With attenuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /private/home/pfz/.cache/huggingface/hub/models--facebook--video_seal/snapshots/8037ef59ba2b2ec8fb8b55298ff37b8ccddd078d/checkpoint.pth with message: <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.9166666865348816, 'psnr': 46.27751541137695, 'ssim': 0.9988591074943542, 'bit_accuracy_qf_80': 0.9270833134651184, 'bit_accuracy_qf_40': 0.8854166865348816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  50%|█████     | 2/4 [00:01<00:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.9895833134651184, 'psnr': 49.10234069824219, 'ssim': 0.9982087016105652, 'bit_accuracy_qf_80': 0.9895833134651184, 'bit_accuracy_qf_40': 0.7395833134651184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  75%|███████▌  | 3/4 [00:06<00:02,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 0.9895833134651184, 'psnr': 45.21706008911133, 'ssim': 0.9980943202972412, 'bit_accuracy_qf_80': 0.9791666865348816, 'bit_accuracy_qf_40': 0.9895833134651184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 4/4 [00:06<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bit_accuracy': 1.0, 'psnr': 46.6027717590332, 'ssim': 0.998041570186615, 'bit_accuracy_qf_80': 0.9895833134651184, 'bit_accuracy_qf_40': 0.96875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory containing videos\n",
    "assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
    "output_dir = \"outputs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Checkpoint\n",
    "ckpt_path = \"videoseal\"\n",
    "# ckpt_path = \"/checkpoint/pfz/2025_logs/0115_vseal_rgb_96bits_nopercep_yuv/_scaling_w=0.05_lambda_d=0.5_extractor_model=sam_small/checkpoint.pth\"\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "\n",
    "# Iterate over all checkpoints\n",
    "wam = setup_model_from_checkpoint(ckpt_path)\n",
    "wam.eval()\n",
    "wam.to(device)\n",
    "\n",
    "# create attenuation\n",
    "attenuation = VarianceBasedJND(\n",
    "    mode=\"variance\",\n",
    "    max_variance_value_for_clipping=300,\n",
    "    min_heatmap_value=0.1,\n",
    "    avg_pool_kernel_size=3\n",
    ")\n",
    "wam.attenuation = attenuation\n",
    "wam.blender.scaling_w = 20.0\n",
    "\n",
    "# Iterate over all video files in the directory\n",
    "files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\")]\n",
    "files = [os.path.join(assets_dir, f) for f in files]\n",
    "\n",
    "for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "    # load image\n",
    "    imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "    imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "    # Watermark embedding\n",
    "    timer.start()\n",
    "    outputs = wam.embed(imgs, is_video=False)\n",
    "    # torch.cuda.synchronize()\n",
    "    # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "    # compute diff\n",
    "    imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "    msgs = outputs[\"msgs\"]  # b k\n",
    "    diff = imgs_w - imgs\n",
    "\n",
    "    # save\n",
    "    timer.start()\n",
    "    base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "    save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "    save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "    save_img(diff[0], f\"{base_save_name}_diff.png\")\n",
    "\n",
    "    # Compute min and max values, reshape, and normalize\n",
    "    min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "    # Save the normalized video\n",
    "    save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "\n",
    "    # Metrics\n",
    "    imgs_aug = imgs_w\n",
    "    outputs = wam.detect(imgs_aug, is_video=False)\n",
    "    metrics = {\n",
    "        \"bit_accuracy\": bit_accuracy(\n",
    "            outputs[\"preds\"][:, 1:],\n",
    "            msgs\n",
    "        ).nanmean().item(),\n",
    "        \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "        \"ssim\": ssim(imgs_w, imgs).item()\n",
    "    }\n",
    "\n",
    "    # Augment video\n",
    "    for qf in [80, 40]:\n",
    "        imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "        # detect\n",
    "        timer.start()\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        preds = outputs[\"preds\"]\n",
    "        bit_preds = preds[:, 1:]  # b k ...\n",
    "        bit_accuracy_ = bit_accuracy(\n",
    "            bit_preds,\n",
    "            msgs\n",
    "        ).nanmean().item()\n",
    "        metrics[f\"bit_accuracy_qf_{qf}\"] = bit_accuracy_\n",
    "    \n",
    "    print(metrics)\n",
    "    del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "# Free model from GPU\n",
    "del wam\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
