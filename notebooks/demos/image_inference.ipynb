{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/09-videoseal/videoseal\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd ../.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusers package not found. Install with pip install diffusers\n"
     ]
    }
   ],
   "source": [
    "from videoseal.utils.display import save_img\n",
    "from videoseal.utils import Timer\n",
    "from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy, psnr, ssim\n",
    "from videoseal.augmentation import Identity, JPEG\n",
    "from videoseal.modules.jnd import JND, VarianceBasedJND\n",
    "\n",
    "import os\n",
    "import omegaconf\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   4%|▍         | 1/23 [00:02<01:03,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/chao.png', 'bit_accuracy': 0.9599999785423279, 'psnr': 47.827083587646484, 'ssim': 0.9989247918128967, 'bit_accuracy_qf80': 0.9700000286102295, 'bit_accuracy_qf40': 0.9100000262260437}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   9%|▊         | 2/23 [00:03<00:29,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/corgi_avocado.png', 'bit_accuracy': 1.0, 'psnr': 49.225772857666016, 'ssim': 0.980121910572052, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.8999999761581421}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  13%|█▎        | 3/23 [00:04<00:23,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/trex_bike.png', 'bit_accuracy': 0.9800000190734863, 'psnr': 49.694114685058594, 'ssim': 0.9973389506340027, 'bit_accuracy_qf80': 0.949999988079071, 'bit_accuracy_qf40': 0.8899999856948853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  17%|█▋        | 4/23 [00:05<00:23,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/tahiti.png', 'bit_accuracy': 1.0, 'psnr': 47.59434127807617, 'ssim': 0.9986631870269775, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.9800000190734863}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  26%|██▌       | 6/23 [00:06<00:11,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/tahiti_512.png', 'bit_accuracy': 1.0, 'psnr': 47.81726837158203, 'ssim': 0.9980719089508057, 'bit_accuracy_qf80': 0.9800000190734863, 'bit_accuracy_qf40': 0.8500000238418579}\n",
      "{'file': '/private/home/pfz/_images/tahiti_256.png', 'bit_accuracy': 1.0, 'psnr': 46.638206481933594, 'ssim': 0.9958131909370422, 'bit_accuracy_qf80': 0.8899999856948853, 'bit_accuracy_qf40': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  30%|███       | 7/23 [00:23<01:36,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/gauguin.jpg', 'bit_accuracy': 0.9900000095367432, 'psnr': 48.776710510253906, 'ssim': 0.9993062615394592, 'bit_accuracy_qf80': 0.9900000095367432, 'bit_accuracy_qf40': 0.9700000286102295}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  35%|███▍      | 8/23 [00:24<01:10,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/gauguin.png', 'bit_accuracy': 0.9700000286102295, 'psnr': 49.25208282470703, 'ssim': 0.9986589550971985, 'bit_accuracy_qf80': 0.949999988079071, 'bit_accuracy_qf40': 0.9300000071525574}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  43%|████▎     | 10/23 [00:25<00:30,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/gauguin_512.png', 'bit_accuracy': 0.9399999976158142, 'psnr': 49.28297424316406, 'ssim': 0.9979521632194519, 'bit_accuracy_qf80': 0.9399999976158142, 'bit_accuracy_qf40': 0.7699999809265137}\n",
      "{'file': '/private/home/pfz/_images/gauguin_256.png', 'bit_accuracy': 0.9900000095367432, 'psnr': 47.47297668457031, 'ssim': 0.9947519302368164, 'bit_accuracy_qf80': 0.9200000166893005, 'bit_accuracy_qf40': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  48%|████▊     | 11/23 [00:26<00:21,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/hific.png', 'bit_accuracy': 1.0, 'psnr': 47.63511276245117, 'ssim': 0.9980044960975647, 'bit_accuracy_qf80': 0.9700000286102295, 'bit_accuracy_qf40': 0.9100000262260437}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  52%|█████▏    | 12/23 [00:27<00:20,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/gfpgan.png', 'bit_accuracy': 0.9800000190734863, 'psnr': 48.04137420654297, 'ssim': 0.9984857439994812, 'bit_accuracy_qf80': 0.9800000190734863, 'bit_accuracy_qf40': 0.949999988079071}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  57%|█████▋    | 13/23 [00:29<00:17,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/woman.png', 'bit_accuracy': 0.9800000190734863, 'psnr': 51.21904754638672, 'ssim': 0.9988647103309631, 'bit_accuracy_qf80': 0.9599999785423279, 'bit_accuracy_qf40': 0.8600000143051147}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  61%|██████    | 14/23 [00:31<00:16,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/gfpgan_hf.png', 'bit_accuracy': 0.9900000095367432, 'psnr': 48.07762145996094, 'ssim': 0.9984259605407715, 'bit_accuracy_qf80': 0.9800000190734863, 'bit_accuracy_qf40': 0.8899999856948853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  65%|██████▌   | 15/23 [00:41<00:33,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/tahiti_photo.png', 'bit_accuracy': 1.0, 'psnr': 50.47669982910156, 'ssim': 0.9988097548484802, 'bit_accuracy_qf80': 0.9800000190734863, 'bit_accuracy_qf40': 0.9900000095367432}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  70%|██████▉   | 16/23 [00:43<00:24,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/pope.png', 'bit_accuracy': 1.0, 'psnr': 51.14977264404297, 'ssim': 0.9942364692687988, 'bit_accuracy_qf80': 0.9900000095367432, 'bit_accuracy_qf40': 0.9399999976158142}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  74%|███████▍  | 17/23 [00:43<00:15,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/tree-ring-bear.png', 'bit_accuracy': 1.0, 'psnr': 47.918853759765625, 'ssim': 0.9971467852592468, 'bit_accuracy_qf80': 0.9700000286102295, 'bit_accuracy_qf40': 0.8700000047683716}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  78%|███████▊  | 18/23 [00:49<00:17,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/duck2.png', 'bit_accuracy': 1.0, 'psnr': 49.20170593261719, 'ssim': 0.9269195199012756, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.8299999833106995}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  83%|████████▎ | 19/23 [00:55<00:17,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/duck1.png', 'bit_accuracy': 1.0, 'psnr': 49.61221694946289, 'ssim': 0.9288146495819092, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.7699999809265137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  87%|████████▋ | 20/23 [01:03<00:16,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/ducks.png', 'bit_accuracy': 1.0, 'psnr': 51.133399963378906, 'ssim': 0.9991388916969299, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.9700000286102295}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  91%|█████████▏| 21/23 [01:06<00:09,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/videoseal.png', 'bit_accuracy': 1.0, 'psnr': 50.16472244262695, 'ssim': 0.9980370402336121, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.9700000286102295}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  96%|█████████▌| 22/23 [01:09<00:04,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/nkl.jpg', 'bit_accuracy': 1.0, 'psnr': 51.34918212890625, 'ssim': 0.9991788864135742, 'bit_accuracy_qf80': 1.0, 'bit_accuracy_qf40': 0.9700000286102295}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 23/23 [01:10<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': '/private/home/pfz/_images/tahiti_wm.jpg', 'bit_accuracy': 1.0, 'psnr': 47.59051513671875, 'ssim': 0.9986249804496765, 'bit_accuracy_qf80': 0.9800000190734863, 'bit_accuracy_qf40': 0.9200000166893005}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory containing videos\n",
    "num_imgs = 50\n",
    "assets_dir = \"/private/home/pfz/_images\"\n",
    "# assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
    "# assets_dir = \"/checkpoint/avseal/datasets/sa-1b-512v2/val-orisize/\"\n",
    "\n",
    "base_output_dir = \"outputs\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# Checkpoint\n",
    "ckpts = {\n",
    "    # \"vs2\": \"/checkpoint/pfz/2025_logs/0306_vseal_ydisc_release_bis/_nbits=256/checkpoint600.pth\",\n",
    "    # \"vs3\": \"/checkpoint/soucek/2025_logs/0926_vseal_aws-dynsize768-aug_size_sweep-discfrom100/_embedder_model=1_augmentation_config=1/checkpoint.pth\",\n",
    "    # \"chunky\": \"chunkyseal\"\n",
    "    # \"invismark\": \"baselines/invismark\"\n",
    "    \"trustmarkp\": \"baselines/trustmark_p\"\n",
    "}\n",
    "\n",
    "for ckpt_name, ckpt_path in ckpts.items():\n",
    "\n",
    "    output_dir = os.path.join(base_output_dir, ckpt_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # a timer to measure the time\n",
    "    timer = Timer()\n",
    "    # Iterate over all checkpoints\n",
    "    wam = setup_model_from_checkpoint(ckpt_path)\n",
    "    wam.eval()\n",
    "    wam.to(device)\n",
    "\n",
    "    # wam.blender.scaling_w = 0.2\n",
    "\n",
    "    # Iterate over all video files in the directory\n",
    "    files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\") or f.endswith(\".jpg\")]\n",
    "    files = [os.path.join(assets_dir, f) for f in files]\n",
    "    files = files[:num_imgs]\n",
    "\n",
    "    for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "        # load image\n",
    "        imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "        imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "        # Watermark embedding\n",
    "        timer.start()\n",
    "        outputs = wam.embed(imgs, is_video=False, lowres_attenuation=False)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # compute diff\n",
    "        imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "        msgs = outputs[\"msgs\"]  # b k\n",
    "        diff = imgs_w - imgs\n",
    "\n",
    "        # save\n",
    "        timer.start()\n",
    "        base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "        # print(f\"saving videos to {base_save_name}\")\n",
    "        save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "        save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "        save_img(20*diff[0].abs(), f\"{base_save_name}_diff.png\")\n",
    "\n",
    "        # Compute min and max values, reshape, and normalize\n",
    "        min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "        # Save the normalized video\n",
    "        save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "        # print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Metrics\n",
    "        imgs_aug = imgs_w\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        metrics = {\n",
    "            \"file\": file,\n",
    "            \"bit_accuracy\": bit_accuracy(\n",
    "                outputs[\"preds\"][:, 1:],\n",
    "                msgs\n",
    "            ).nanmean().item(),\n",
    "            \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "            \"ssim\": ssim(imgs_w, imgs).item()\n",
    "        }\n",
    "\n",
    "        # Augment video\n",
    "        # print(f\"compressing and detecting watermarks\")\n",
    "        for qf in [80, 40]:\n",
    "            imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "            # detect\n",
    "            timer.start()\n",
    "            outputs = wam.detect(imgs_aug, is_video=True)\n",
    "            preds = outputs[\"preds\"]\n",
    "            # print(preds)\n",
    "            bit_preds = preds[:, 1:]  # b k ...\n",
    "            bit_accuracy_ = bit_accuracy(\n",
    "                bit_preds,\n",
    "                msgs\n",
    "            ).nanmean().item()\n",
    "            \n",
    "            metrics[f\"bit_accuracy_qf{qf}\"] = bit_accuracy_\n",
    "\n",
    "        print(metrics)\n",
    "\n",
    "        del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "    # Free model from GPU\n",
    "    del wam\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With attenuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing videos\n",
    "assets_dir = \"/checkpoint/pfz/projects/videoseal/assets/imgs\"\n",
    "output_dir = \"outputs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Checkpoint\n",
    "ckpt_path = \"videoseal\"\n",
    "# ckpt_path = \"/checkpoint/pfz/2025_logs/0115_vseal_rgb_96bits_nopercep_yuv/_scaling_w=0.05_lambda_d=0.5_extractor_model=sam_small/checkpoint.pth\"\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "\n",
    "# Iterate over all checkpoints\n",
    "wam = setup_model_from_checkpoint(ckpt_path)\n",
    "wam.eval()\n",
    "wam.to(device)\n",
    "\n",
    "# create attenuation\n",
    "attenuation = VarianceBasedJND(\n",
    "    mode=\"variance\",\n",
    "    max_variance_value_for_clipping=300,\n",
    "    min_heatmap_value=0.1,\n",
    "    avg_pool_kernel_size=3\n",
    ")\n",
    "wam.attenuation = attenuation\n",
    "wam.blender.scaling_w = 20.0\n",
    "\n",
    "# Iterate over all video files in the directory\n",
    "files = [f for f in os.listdir(assets_dir) if f.endswith(\".png\")]\n",
    "files = [os.path.join(assets_dir, f) for f in files]\n",
    "\n",
    "for file in tqdm(files, desc=f\"Processing Images\"):\n",
    "    # load image\n",
    "    imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "    imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "    # Watermark embedding\n",
    "    timer.start()\n",
    "    outputs = wam.embed(imgs, is_video=False)\n",
    "    # torch.cuda.synchronize()\n",
    "    # print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "    # compute diff\n",
    "    imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "    msgs = outputs[\"msgs\"]  # b k\n",
    "    diff = imgs_w - imgs\n",
    "\n",
    "    # save\n",
    "    timer.start()\n",
    "    base_save_name = os.path.join(output_dir, os.path.basename(file).replace(\".png\", \"\"))\n",
    "    save_img(imgs[0], f\"{base_save_name}_ori.png\")\n",
    "    save_img(imgs_w[0], f\"{base_save_name}_wm.png\")\n",
    "    save_img(diff[0], f\"{base_save_name}_diff.png\")\n",
    "\n",
    "    # Compute min and max values, reshape, and normalize\n",
    "    min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "    normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "    # Save the normalized video\n",
    "    save_img(normalized_images[0], f\"{base_save_name}_diff_norm.png\")\n",
    "\n",
    "    # Metrics\n",
    "    imgs_aug = imgs_w\n",
    "    outputs = wam.detect(imgs_aug, is_video=False)\n",
    "    metrics = {\n",
    "        \"bit_accuracy\": bit_accuracy(\n",
    "            outputs[\"preds\"][:, 1:],\n",
    "            msgs\n",
    "        ).nanmean().item(),\n",
    "        \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "        \"ssim\": ssim(imgs_w, imgs).item()\n",
    "    }\n",
    "\n",
    "    # Augment video\n",
    "    for qf in [80, 40]:\n",
    "        imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "        # detect\n",
    "        timer.start()\n",
    "        outputs = wam.detect(imgs_aug, is_video=False)\n",
    "        preds = outputs[\"preds\"]\n",
    "        bit_preds = preds[:, 1:]  # b k ...\n",
    "        bit_accuracy_ = bit_accuracy(\n",
    "            bit_preds,\n",
    "            msgs\n",
    "        ).nanmean().item()\n",
    "        metrics[f\"bit_accuracy_qf_{qf}\"] = bit_accuracy_\n",
    "    \n",
    "    print(metrics)\n",
    "    del outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "# Free model from GPU\n",
    "del wam\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
