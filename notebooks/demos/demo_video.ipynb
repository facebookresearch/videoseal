{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/hadyelsahar/work/code/videoseal/videoseal\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import omegaconf\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "import subprocess\n",
    "import io\n",
    "import av\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "from videoseal.models import Wam, build_embedder, build_extractor\n",
    "from videoseal.augmentation.video import compress_decompress\n",
    "from videoseal.augmentation.augmenter import Augmenter\n",
    "from videoseal.evals.metrics import psnr, ssim\n",
    "from videoseal.data.transforms import default_transform, normalize_img, unnormalize_img\n",
    "from videoseal.data.datasets import VideoDataset\n",
    "from videoseal.utils.display import save_vid, get_fps\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:videoseal.data.datasets:Loading videos from assets/videos\n",
      "INFO:videoseal.data.datasets:Found 5 videos in assets/videos\n",
      "Processing videos in assets/videos: 100%|██████████| 5/5 [00:00<00:00, 117817.53it/s]\n",
      "INFO:videoseal.data.datasets:Total videos loaded from assets/videos: 5\n"
     ]
    }
   ],
   "source": [
    "# load video\n",
    "video_dir = \"assets/videos\"\n",
    "video_path = \"assets/videos/sav_055001.mp4\"\n",
    "# !ffprobe -v error -show_entries stream=r_frame_rate -of default=noprint_wrappers=1:nokey=1 assets/videos/sav_013754.mp4\n",
    "\n",
    "fps = 24 // 1\n",
    "frames_per_clip = fps * 3 # 3s\n",
    "frame_step = 1\n",
    "\n",
    "vid_dataset = VideoDataset(\n",
    "    folder_paths = [video_dir], \n",
    "    frames_per_clip = frames_per_clip,\n",
    "    frame_step = frame_step,\n",
    "    output_resolution=(1920, 1080),\n",
    "    flatten_clips_to_frames=False,\n",
    ")\n",
    "\n",
    "video_tensor, masks, _ =  vid_dataset.__getitem__(0)\n",
    "\n",
    "vid = normalize_img(video_tensor)\n",
    "\n",
    "n = 10\n",
    "vid = vid.to(device)[:n]\n",
    "masks = masks.to(device)[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoseal.augmentation.augmenter import Augmenter\n",
    "from videoseal.modules.jnd import JND\n",
    "from videoseal.models.embedder import Embedder\n",
    "from videoseal.models.extractor import Extractor\n",
    "from videoseal.models.video_wam import VideoWam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(train_dir='/datasets01/COCO/060817/train2014/', train_annotation_file='/datasets01/COCO/060817/annotations/instances_train2014.json', val_dir='/datasets01/COCO/060817/val2014/', val_annotation_file='/datasets01/COCO/060817/annotations/instances_val2014.json', output_dir='/checkpoint/pfz/2024_logs/0911_vseal_pw/_extractor_model=sam_tiny', embedder_config='configs/embedder.yaml', augmentation_config='configs/simple_augs.yaml', extractor_config='configs/extractor.yaml', attenuation_config='configs/attenuation.yaml', embedder_model='unet_small2', extractor_model='sam_tiny', nbits=32, img_size=256, img_size_extractor=256, attenuation='None', scaling_w=0.4, scaling_w_schedule=None, scaling_i=1.0, threshold_mask=0.6, optimizer='AdamW,lr=1e-4', optimizer_d=None, scheduler='CosineLRScheduler,lr_min=1e-6,t_initial=100,warmup_lr_init=1e-6,warmup_t=5', epochs=100, batch_size=16, batch_size_eval=32, temperature=1.0, workers=8, resume_from=None, lambda_det=0.0, lambda_dec=1.0, lambda_i=0.0, lambda_d=0.0, balanced=False, total_gnorm=0.0, perceptual_loss='mse', disc_start=0, disc_num_layers=2, only_eval=False, eval_freq=5, full_eval_freq=50, saveimg_freq=5, saveckpt_freq=50, seed=0, debug_slurm=False, local_rank=0, master_port=13946, is_slurm_job=True, job_id='32284190', n_nodes=1, node_id=0, global_rank=0, world_size=8, n_gpu_per_node=8, master_addr='learnfair7487', is_master=True, multi_node=False, distributed=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1757216/4022889192.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /checkpoint/pfz/2024_logs/0911_vseal_pw/_extractor_model=sam_tiny/checkpoint.pth\n",
      "__log__:{\"train_dir\": \"/datasets01/COCO/060817/train2014/\", \"train_annotation_file\": \"/datasets01/COCO/060817/annotations/instances_train2014.json\", \"val_dir\": \"/datasets01/COCO/060817/val2014/\", \"val_annotation_file\": \"/datasets01/COCO/060817/annotations/instances_val2014.json\", \"output_dir\": \"/checkpoint/pfz/2024_logs/0911_vseal_pw/_extractor_model=sam_tiny\", \"embedder_config\": \"configs/embedder.yaml\", \"augmentation_config\": \"configs/simple_augs.yaml\", \"extractor_config\": \"configs/extractor.yaml\", \"attenuation_config\": \"configs/attenuation.yaml\", \"embedder_model\": \"unet_small2\", \"extractor_model\": \"sam_tiny\", \"nbits\": 32, \"img_size\": 256, \"img_size_extractor\": 256, \"attenuation\": \"None\", \"scaling_w\": 0.4, \"scaling_w_schedule\": null, \"scaling_i\": 1.0, \"threshold_mask\": 0.6, \"optimizer\": \"AdamW,lr=1e-4\", \"optimizer_d\": null, \"scheduler\": \"CosineLRScheduler,lr_min=1e-6,t_initial=100,warmup_lr_init=1e-6,warmup_t=5\", \"epochs\": 100, \"batch_size\": 16, \"batch_size_eval\": 32, \"temperature\": 1.0, \"workers\": 8, \"resume_from\": null, \"lambda_det\": 0.0, \"lambda_dec\": 1.0, \"lambda_i\": 0.0, \"lambda_d\": 0.0, \"balanced\": false, \"total_gnorm\": 0.0, \"perceptual_loss\": \"mse\", \"disc_start\": 0, \"disc_num_layers\": 2, \"only_eval\": false, \"eval_freq\": 5, \"full_eval_freq\": 50, \"saveimg_freq\": 5, \"saveckpt_freq\": 50, \"seed\": 0, \"debug_slurm\": false, \"local_rank\": 0, \"master_port\": 13946, \"is_slurm_job\": true, \"job_id\": \"32284190\", \"n_nodes\": 1, \"node_id\": 0, \"global_rank\": 0, \"world_size\": 8, \"n_gpu_per_node\": 8, \"master_addr\": \"learnfair7487\", \"is_master\": true, \"multi_node\": false, \"distributed\": true}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VideoWam(\n",
       "  (embedder): UnetEmbedder(\n",
       "    (unet): UNetMsg(\n",
       "      (msg_processor): MsgProcessor(\n",
       "        (msg_embeddings): Embedding(64, 64)\n",
       "      )\n",
       "      (inc): ResnetBlock(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ChanRMSNorm()\n",
       "          (2): SiLU()\n",
       "          (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ChanRMSNorm()\n",
       "          (5): SiLU()\n",
       "        )\n",
       "        (res_conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): DBlock(\n",
       "          (down): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (conv): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): DBlock(\n",
       "          (down): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (conv): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): DBlock(\n",
       "          (down): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (conv): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (bottleneck): BottleNeck(\n",
       "        (model): Sequential(\n",
       "          (0): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (4): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (5): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (6): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (7): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): UBlock(\n",
       "          (up): Upsample(\n",
       "            (upsample_block): Sequential(\n",
       "              (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "              (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (2): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "              (3): LayerNorm()\n",
       "              (4): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (conv): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): UBlock(\n",
       "          (up): Upsample(\n",
       "            (upsample_block): Sequential(\n",
       "              (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "              (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "              (3): LayerNorm()\n",
       "              (4): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (conv): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): UBlock(\n",
       "          (up): Upsample(\n",
       "            (upsample_block): Sequential(\n",
       "              (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "              (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "              (2): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "              (3): LayerNorm()\n",
       "              (4): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (conv): ResnetBlock(\n",
       "            (double_conv): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ChanRMSNorm()\n",
       "              (2): SiLU()\n",
       "              (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (4): ChanRMSNorm()\n",
       "              (5): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (outc): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (msg_processor): MsgProcessor(\n",
       "      (msg_embeddings): Embedding(64, 64)\n",
       "    )\n",
       "  )\n",
       "  (detector): SegmentationExtractor(\n",
       "    (image_encoder): ImageEncoderViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (lin2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (neck): Sequential(\n",
       "        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LayerNorm()\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (3): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (pixel_decoder): PixelDecoder(\n",
       "      (output_upscaling): Sequential(\n",
       "        (0): Upsample(\n",
       "          (upsample_block): Sequential(\n",
       "            (0): Upsample(scale_factor=1.0, mode='bilinear')\n",
       "            (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "            (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "            (3): LayerNorm()\n",
       "            (4): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear): Linear(in_features=192, out_features=33, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (augmenter): Augmenter(augs=['Identity', 'JPEG', 'Resize', 'Crop', 'Rotate', 'HorizontalFlip', 'Perspective', 'GaussianBlur', 'MedianFilter', 'Brightness', 'Contrast', 'Saturation', 'Hue'], probs=tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]))\n",
       "  (resize_to): Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model_from_checkpoint(exp_dir, exp_name):\n",
    "    logfile_path = os.path.join(exp_dir, 'logs', exp_name + '.stdout')\n",
    "    ckpt_path = os.path.join(exp_dir, exp_name, 'checkpoint.pth')\n",
    "\n",
    "    # Load parameters from log file\n",
    "    with open(logfile_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if '__log__:' in line:\n",
    "                params = json.loads(line.split('__log__:')[1].strip())\n",
    "                break\n",
    "\n",
    "    # Create an argparse Namespace object from the parameters\n",
    "    args = argparse.Namespace(**params)\n",
    "    print(args)\n",
    "    \n",
    "    # Load configurations\n",
    "    for path in [args.embedder_config, args.extractor_config, args.augmentation_config]:\n",
    "        path = os.path.join(exp_dir, \"code\", path)\n",
    "    # embedder\n",
    "    embedder_cfg = omegaconf.OmegaConf.load(args.embedder_config)\n",
    "    args.embedder_model = args.embedder_model or embedder_cfg.model\n",
    "    embedder_params = embedder_cfg[args.embedder_model]\n",
    "    # extractor\n",
    "    extractor_cfg = omegaconf.OmegaConf.load(args.extractor_config)\n",
    "    args.extractor_model = args.extractor_model or extractor_cfg.model\n",
    "    extractor_params = extractor_cfg[args.extractor_model]\n",
    "    # augmenter\n",
    "    augmenter_cfg = omegaconf.OmegaConf.load(args.augmentation_config)\n",
    "    \n",
    "    # Build models\n",
    "    embedder = build_embedder(args.embedder_model, embedder_params, args.nbits)\n",
    "    extractor = build_extractor(extractor_cfg.model, extractor_params, args.img_size_extractor, args.nbits)\n",
    "    augmenter = Augmenter(**augmenter_cfg)\n",
    "    \n",
    "    # Build the complete model\n",
    "    wam = VideoWam(embedder, extractor, augmenter, \n",
    "                   scaling_w=args.scaling_w, scaling_i=args.scaling_i)\n",
    "    \n",
    "    # Load the model weights\n",
    "    if os.path.exists(ckpt_path):\n",
    "        checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "        wam.load_state_dict(checkpoint['model'])\n",
    "        print(\"Model loaded successfully from\", ckpt_path)\n",
    "        print(line)\n",
    "    else:\n",
    "        print(\"Checkpoint path does not exist:\", ckpt_path)\n",
    "    \n",
    "    return wam\n",
    "\n",
    "# Example usage\n",
    "exp_dir = '/checkpoint/pfz/2024_logs/0911_vseal_pw'\n",
    "exp_name = '_extractor_model=sam_tiny'\n",
    "\n",
    "wam = load_model_from_checkpoint(exp_dir, exp_name)\n",
    "wam.eval()\n",
    "wam.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attenuation_cfg = \"configs/attenuation.yaml\"\n",
    "attenuation = \"jnd_1_3\"\n",
    "attenuation_cfg = omegaconf.OmegaConf.load(attenuation_cfg)[attenuation]\n",
    "attenuation = JND(**attenuation_cfg).to(device)\n",
    "attenuation.preprocess = unnormalize_img\n",
    "attenuation.postprocess = normalize_img\n",
    "\n",
    "wam.attenuation = attenuation\n",
    "wam.attenuation = attenuation\n",
    "wam.scaling_w = 3.0\n",
    "wam.scaling_i = 1.0\n",
    "\n",
    "# wam.attenuation = None\n",
    "# wam.scaling_w = 0.4\n",
    "# wam.scaling_i = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before compression\n",
      "PSNR: 33.56, SSIM: 0.98, Bit accuracy: 0.94\n",
      "After compression\n",
      "CRF: 15, PSNR: 33.02, SSIM: 0.98, Bit accuracy: 0.94\n",
      "CRF: 25, PSNR: 31.53, SSIM: 0.94, Bit accuracy: 0.94\n",
      "CRF: 50, PSNR: 21.56, SSIM: 0.55, Bit accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "msg = wam.get_random_msg()\n",
    "\n",
    "# vid = normalize_img(video_tensor / 255)\n",
    "vid = normalize_img(video_tensor)\n",
    "\n",
    "vid = vid.to(device)\n",
    "msg = msg.to(device)\n",
    "vid_w = wam.video_embed(vid, msg)\n",
    "preds = wam.video_detect(vid_w)\n",
    "\n",
    "psnr_val = psnr(vid_w, vid).mean().item()\n",
    "ssim_val = ssim(vid_w, vid).mean().item()\n",
    "bit_acc = (msg == preds).float().mean().item()\n",
    "print(\"Before compression\")\n",
    "print(f\"PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.2f}, Bit accuracy: {bit_acc:.2f}\")\n",
    "\n",
    "# compress and decompress\n",
    "print(\"After compression\")\n",
    "for crf in [15, 25, 50]:\n",
    "    vid_w_comp = compress_decompress(vid_w, codec='libx264', crf=crf)\n",
    "    preds_comp = wam.video_detect(vid_w_comp)\n",
    "    bit_acc_comp = (msg == preds_comp).float().mean().item()\n",
    "\n",
    "    psnr_val = psnr(vid_w_comp, vid).mean().item()\n",
    "    ssim_val = ssim(vid_w_comp, vid).mean().item()\n",
    "    print(f\"CRF: {crf}, PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.2f}, Bit accuracy: {bit_acc_comp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ffmpeg -i output_w.mp4 -i  output_o.mp4 -filter_complex ssim -f null - 2>&1 | grep \" SSIM \"\n",
    "# # https://stackoverflow.com/questions/62061410/can-someone-help-me-to-install-the-netflixs-vmaf-library-in-ubuntu\n",
    "# !ffmpeg -i output_w.mp4 -i  output_o.mp4 -filter_complex libvmaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoseal.utils.display import save_vid\n",
    "\n",
    "out_path = \"./outputs/\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "# Save videos in the specified output directory\n",
    "\n",
    "raw_path = os.path.join(out_path, \"output_raw.mp4\")\n",
    "wmed_path = os.path.join(out_path, \"output_wmed.mp4\")\n",
    "\n",
    "save_vid(vid, raw_path, fps)\n",
    "save_vid(vid_w, wmed_path, fps)\n",
    "save_vid(vid - vid_w, os.path.join(out_path, \"output_wm.mp4\"), fps)\n",
    "\n",
    "# get video fps and durations\n",
    "fps, frame_count = get_fps(raw_path)\n",
    "duration = frame_count / fps\n",
    "\n",
    "ori_fps, ori_frame_count = get_fps(wmed_path)\n",
    "ori_duration = ori_frame_count / ori_fps\n",
    "print(f\"Output video fps: {fps}, duration: {duration:.2f}s, Original video fps: {ori_fps}, duration: {ori_duration:.2f}s\")\n",
    "\n",
    "# get sizes\n",
    "size = os.path.getsize(raw_path) / 1e6\n",
    "original_size = os.path.getsize(wmed_path) / 1e6\n",
    "size_per_sec = size / duration\n",
    "original_size_per_sec = original_size / ori_duration\n",
    "print(f\"Output video size: {size:.2f} MB, Original video size: {original_size:.2f} MB\")\n",
    "print(f\"Output video size per sec: {size_per_sec:.2f} MB, Original video size per sec: {original_size_per_sec:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressed_video.shape -> torch.Size([t, c, h, w])\n",
    "def plot_images_from_video_tensor(video_tensor, n=5):\n",
    "    # prepare images\n",
    "    video_tensor = video_tensor.clamp(0, 1).permute(0, 2, 3, 1)  # t c h w -> t w h c\n",
    "    video_tensor = video_tensor.cpu().numpy() \n",
    "    # plot\n",
    "    indexes = np.linspace(0, len(video_tensor)-1, n).astype(int)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n*3, 3))\n",
    "    for ii, idx in enumerate(indexes):\n",
    "        axes[ii].imshow(video_tensor[idx])\n",
    "        axes[ii].axis('off')\n",
    "        axes[ii].set_title(f\"Frame {idx}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_images_from_video_tensor(vid_w-vid, n=5)\n",
    "plot_images_from_video_tensor(video_tensor, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = wam(torch.stack([vid,vid]) , torch.stack([masks,masks]), is_video=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msgs': tensor([[0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "          1, 0, 1, 1, 1, 1, 1, 0]], device='cuda:0'),\n",
       " 'masks': tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "         [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "         [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "         [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "         [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0'),\n",
       " 'imgs_w': tensor([[[[ 6.8952e-01,  8.0806e-01,  4.2998e-01,  ...,  1.0447e+00,\n",
       "             1.0626e+00,  1.0634e+00],\n",
       "           [ 6.5004e-01,  7.8573e-01,  4.0769e-01,  ...,  1.0283e+00,\n",
       "             1.0460e+00,  1.0466e+00],\n",
       "           [ 6.6194e-01,  8.1479e-01,  3.8539e-01,  ...,  1.0119e+00,\n",
       "             1.0465e+00,  1.0469e+00],\n",
       "           ...,\n",
       "           [ 7.2434e-01,  7.6788e-01,  6.5729e-01,  ...,  9.1906e-01,\n",
       "             1.1087e+00,  1.0415e+00],\n",
       "           [ 7.4281e-01,  8.1964e-01,  7.7660e-01,  ...,  8.7811e-01,\n",
       "             1.0807e+00,  1.0949e+00],\n",
       "           [ 7.7840e-01,  8.2003e-01,  8.1029e-01,  ...,  8.2004e-01,\n",
       "             1.0527e+00,  1.0284e+00]],\n",
       " \n",
       "          [[ 3.5753e-01,  5.0745e-01,  4.6480e-01,  ...,  6.8444e-01,\n",
       "             6.6697e-01,  6.6702e-01],\n",
       "           [ 3.5840e-01,  5.2149e-01,  4.7450e-01,  ...,  6.8452e-01,\n",
       "             6.6708e-01,  6.6714e-01],\n",
       "           [ 4.1179e-01,  5.8805e-01,  4.8420e-01,  ...,  6.8460e-01,\n",
       "             6.8469e-01,  6.8478e-01],\n",
       "           ...,\n",
       "           [ 7.9268e-01,  8.4403e-01,  8.2534e-01,  ...,  6.5710e-01,\n",
       "             8.7096e-01,  8.2221e-01],\n",
       "           [ 6.3718e-01,  7.2396e-01,  9.5080e-01,  ...,  6.1570e-01,\n",
       "             8.4581e-01,  8.8334e-01],\n",
       "           [ 6.7426e-01,  7.2645e-01,  9.8872e-01,  ...,  5.5680e-01,\n",
       "             8.2067e-01,  8.2193e-01]],\n",
       " \n",
       "          [[ 4.4088e-01,  5.5057e-01,  2.2454e-01,  ...,  2.3112e+00,\n",
       "             2.3114e+00,  2.3117e+00],\n",
       "           [ 4.2313e-01,  5.5599e-01,  2.3570e-01,  ...,  2.3122e+00,\n",
       "             2.3124e+00,  2.3125e+00],\n",
       "           [ 4.5767e-01,  6.1370e-01,  2.4686e-01,  ...,  2.3133e+00,\n",
       "             2.3308e+00,  2.3308e+00],\n",
       "           ...,\n",
       "           [ 8.8805e-01,  9.5895e-01,  9.7756e-01,  ...,  1.5383e+00,\n",
       "             1.7709e+00,  1.7421e+00],\n",
       "           [ 7.9797e-01,  9.0483e-01,  1.0640e+00,  ...,  1.5130e+00,\n",
       "             1.7627e+00,  1.8208e+00],\n",
       "           [ 8.2989e-01,  9.0299e-01,  1.0981e+00,  ...,  1.4702e+00,\n",
       "             1.7545e+00,  1.7774e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 6.8952e-01,  8.0806e-01,  4.2998e-01,  ...,  1.0447e+00,\n",
       "             1.0626e+00,  1.0634e+00],\n",
       "           [ 6.5004e-01,  7.8573e-01,  4.0769e-01,  ...,  1.0283e+00,\n",
       "             1.0460e+00,  1.0466e+00],\n",
       "           [ 6.6194e-01,  8.1479e-01,  3.8539e-01,  ...,  1.0119e+00,\n",
       "             1.0465e+00,  1.0469e+00],\n",
       "           ...,\n",
       "           [ 6.2160e-01,  6.4800e-01,  4.6892e-01,  ...,  4.9094e-01,\n",
       "             1.3261e-01,  1.6815e-01],\n",
       "           [ 6.7431e-01,  6.1414e-01,  5.1973e-01,  ...,  6.2124e-01,\n",
       "             3.2721e-01,  2.0443e-01],\n",
       "           [ 8.8115e-01,  5.9741e-01,  5.7054e-01,  ...,  6.6592e-01,\n",
       "             4.5331e-01,  1.8933e-01]],\n",
       " \n",
       "          [[ 3.5753e-01,  5.0745e-01,  4.6480e-01,  ...,  6.8444e-01,\n",
       "             6.6697e-01,  6.6702e-01],\n",
       "           [ 3.5840e-01,  5.2149e-01,  4.7450e-01,  ...,  6.8452e-01,\n",
       "             6.6708e-01,  6.6714e-01],\n",
       "           [ 4.1179e-01,  5.8805e-01,  4.8420e-01,  ...,  6.8460e-01,\n",
       "             6.8469e-01,  6.8478e-01],\n",
       "           ...,\n",
       "           [ 6.8764e-01,  7.2148e-01,  8.0784e-01,  ...,  2.1943e-01,\n",
       "            -1.2694e-01, -7.0650e-02],\n",
       "           [ 7.4222e-01,  6.8895e-01,  8.1075e-01,  ...,  3.5310e-01,\n",
       "             7.5503e-02, -2.7021e-02],\n",
       "           [ 9.5437e-01,  6.7393e-01,  8.6618e-01,  ...,  3.9923e-01,\n",
       "             2.0792e-01, -3.5913e-02]],\n",
       " \n",
       "          [[ 4.4088e-01,  5.5057e-01,  2.2454e-01,  ...,  2.3112e+00,\n",
       "             2.3114e+00,  2.3117e+00],\n",
       "           [ 4.2313e-01,  5.5599e-01,  2.3570e-01,  ...,  2.3122e+00,\n",
       "             2.3124e+00,  2.3125e+00],\n",
       "           [ 4.5767e-01,  6.1370e-01,  2.4686e-01,  ...,  2.3133e+00,\n",
       "             2.3308e+00,  2.3308e+00],\n",
       "           ...,\n",
       "           [ 8.1834e-01,  8.7181e-01,  8.5556e-01,  ...,  1.0677e+00,\n",
       "             7.4261e-01,  8.1838e-01],\n",
       "           [ 8.6769e-01,  8.3511e-01,  9.0711e-01,  ...,  1.2167e+00,\n",
       "             9.6099e-01,  8.7959e-01],\n",
       "           [ 1.0739e+00,  8.1585e-01,  9.5866e-01,  ...,  1.2785e+00,\n",
       "             1.1096e+00,  8.8851e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 6.8952e-01,  8.0806e-01,  4.2998e-01,  ...,  1.0447e+00,\n",
       "             1.0626e+00,  1.0634e+00],\n",
       "           [ 6.5004e-01,  7.8573e-01,  4.0769e-01,  ...,  1.0283e+00,\n",
       "             1.0460e+00,  1.0466e+00],\n",
       "           [ 6.6194e-01,  8.1479e-01,  3.8539e-01,  ...,  1.0119e+00,\n",
       "             1.0294e+00,  1.0298e+00],\n",
       "           ...,\n",
       "           [ 6.0447e-01,  6.6513e-01,  6.4016e-01,  ...,  5.5944e-01,\n",
       "             2.6961e-01,  4.8272e-02],\n",
       "           [ 7.0856e-01,  7.1689e-01,  6.5673e-01,  ...,  2.6162e-01,\n",
       "             2.4158e-01,  2.0443e-01],\n",
       "           [ 7.2703e-01,  7.3441e-01,  6.5616e-01,  ...,  1.5175e-02,\n",
       "             2.5191e-02,  2.2358e-01]],\n",
       " \n",
       "          [[ 3.5753e-01,  5.0745e-01,  4.6480e-01,  ...,  6.8444e-01,\n",
       "             6.6697e-01,  6.6702e-01],\n",
       "           [ 3.5840e-01,  5.2149e-01,  4.7450e-01,  ...,  6.8452e-01,\n",
       "             6.6708e-01,  6.6714e-01],\n",
       "           [ 4.1179e-01,  5.8805e-01,  4.8420e-01,  ...,  6.8460e-01,\n",
       "             6.6718e-01,  6.6727e-01],\n",
       "           ...,\n",
       "           [ 7.0515e-01,  7.7400e-01,  9.8291e-01,  ...,  2.8945e-01,\n",
       "             1.3113e-02, -1.9320e-01],\n",
       "           [ 8.1225e-01,  8.2901e-01,  1.0033e+00,  ..., -1.4550e-02,\n",
       "            -1.2032e-02, -2.7021e-02],\n",
       "           [ 8.3182e-01,  8.4900e-01,  1.0062e+00,  ..., -2.6603e-01,\n",
       "            -2.2975e-01, -8.9911e-04]],\n",
       " \n",
       "          [[ 4.4088e-01,  5.5057e-01,  2.2454e-01,  ...,  2.3112e+00,\n",
       "             2.3114e+00,  2.3117e+00],\n",
       "           [ 4.2313e-01,  5.5599e-01,  2.3570e-01,  ...,  2.3122e+00,\n",
       "             2.3124e+00,  2.3125e+00],\n",
       "           [ 4.5767e-01,  6.1370e-01,  2.4686e-01,  ...,  2.3133e+00,\n",
       "             2.3133e+00,  2.3134e+00],\n",
       "           ...,\n",
       "           [ 8.8805e-01,  9.7638e-01,  1.1170e+00,  ...,  1.1374e+00,\n",
       "             8.8204e-01,  6.9638e-01],\n",
       "           [ 9.8969e-01,  1.0268e+00,  1.1337e+00,  ...,  8.5066e-01,\n",
       "             8.7384e-01,  8.7959e-01],\n",
       "           [ 1.0042e+00,  1.0424e+00,  1.1330e+00,  ...,  6.1618e-01,\n",
       "             6.7392e-01,  9.2337e-01]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 7.3169e-01,  7.8392e-01,  3.7379e-01,  ...,  1.0684e+00,\n",
       "             1.0705e+00,  1.0726e+00],\n",
       "           [ 7.4260e-01,  7.4319e-01,  3.3278e-01,  ...,  1.0404e+00,\n",
       "             1.0422e+00,  1.0440e+00],\n",
       "           [ 7.5351e-01,  7.3670e-01,  3.0890e-01,  ...,  1.0125e+00,\n",
       "             1.0140e+00,  1.0155e+00],\n",
       "           ...,\n",
       "           [ 8.0826e-01,  7.6514e-01,  7.2202e-01,  ...,  8.7771e-01,\n",
       "             8.6029e-01,  8.4288e-01],\n",
       "           [ 7.2622e-01,  7.5060e-01,  6.8935e-01,  ...,  7.6658e-01,\n",
       "             7.4519e-01,  7.2380e-01],\n",
       "           [ 6.9556e-01,  7.3606e-01,  6.2243e-01,  ...,  7.5819e-01,\n",
       "             6.9858e-01,  6.5609e-01]],\n",
       " \n",
       "          [[ 4.0165e-01,  4.8262e-01,  3.8852e-01,  ...,  6.8562e-01,\n",
       "             6.8570e-01,  6.8578e-01],\n",
       "           [ 4.5569e-01,  4.7956e-01,  3.8088e-01,  ...,  6.8587e-01,\n",
       "             6.8598e-01,  6.8609e-01],\n",
       "           [ 4.9223e-01,  4.9401e-01,  3.9074e-01,  ...,  6.8612e-01,\n",
       "             6.8626e-01,  6.8640e-01],\n",
       "           ...,\n",
       "           [ 7.2682e-01,  6.9066e-01,  8.6459e-01,  ...,  5.1666e-01,\n",
       "             5.2666e-01,  5.3667e-01],\n",
       "           [ 6.3990e-01,  6.7423e-01,  8.3111e-01,  ...,  4.0751e-01,\n",
       "             4.1755e-01,  4.2760e-01],\n",
       "           [ 6.0551e-01,  6.5780e-01,  7.6261e-01,  ...,  4.0340e-01,\n",
       "             3.7847e-01,  3.7105e-01]],\n",
       " \n",
       "          [[ 5.6085e-01,  6.0109e-01,  2.4046e-01,  ...,  2.3313e+00,\n",
       "             2.3314e+00,  2.3315e+00],\n",
       "           [ 5.9523e-01,  5.8873e-01,  2.3364e-01,  ...,  2.3320e+00,\n",
       "             2.3321e+00,  2.3321e+00],\n",
       "           [ 5.7732e-01,  5.5894e-01,  1.9197e-01,  ...,  2.3328e+00,\n",
       "             2.3328e+00,  2.3328e+00],\n",
       "           ...,\n",
       "           [ 7.7506e-01,  7.4973e-01,  8.6384e-01,  ...,  1.5186e+00,\n",
       "             1.5383e+00,  1.5580e+00],\n",
       "           [ 6.9000e-01,  7.3454e-01,  8.3138e-01,  ...,  1.4188e+00,\n",
       "             1.4380e+00,  1.4573e+00],\n",
       "           [ 6.5722e-01,  7.1936e-01,  7.6407e-01,  ...,  1.4235e+00,\n",
       "             1.4075e+00,  1.4088e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 8.2023e-01,  8.4248e-01,  4.1949e-01,  ...,  1.0766e+00,\n",
       "             1.0777e+00,  1.0787e+00],\n",
       "           [ 7.9433e-01,  8.1573e-01,  3.9189e-01,  ...,  1.0563e+00,\n",
       "             1.0572e+00,  1.0581e+00],\n",
       "           [ 7.6844e-01,  7.8898e-01,  3.6428e-01,  ...,  1.0361e+00,\n",
       "             1.0368e+00,  1.0374e+00],\n",
       "           ...,\n",
       "           [ 8.8775e-01,  7.5681e-01,  5.5738e-01,  ...,  9.3437e-01,\n",
       "             9.5422e-01,  1.2309e+00],\n",
       "           [ 8.9210e-01,  7.4265e-01,  3.3634e-01,  ...,  1.2111e+00,\n",
       "             1.1761e+00,  1.2440e+00],\n",
       "           [ 7.5944e-01,  8.4836e-01,  4.5779e-01,  ...,  1.2994e+00,\n",
       "             1.2268e+00,  1.1714e+00]],\n",
       " \n",
       "          [[ 4.5442e-01,  4.9884e-01,  4.0321e-01,  ...,  6.8488e-01,\n",
       "             6.8491e-01,  6.8494e-01],\n",
       "           [ 4.7305e-01,  5.1304e-01,  4.1299e-01,  ...,  6.8500e-01,\n",
       "             6.8506e-01,  6.8512e-01],\n",
       "           [ 5.0917e-01,  5.4475e-01,  4.4027e-01,  ...,  6.8512e-01,\n",
       "             6.8521e-01,  6.8529e-01],\n",
       "           ...,\n",
       "           [ 8.0579e-01,  6.8362e-01,  7.0151e-01,  ...,  6.0030e-01,\n",
       "             6.5026e-01,  9.6283e-01],\n",
       "           [ 8.0616e-01,  6.6704e-01,  4.7541e-01,  ...,  8.9491e-01,\n",
       "             8.9254e-01,  9.9520e-01],\n",
       "           [ 6.6646e-01,  7.7302e-01,  5.9946e-01,  ...,  9.9695e-01,\n",
       "             9.5974e-01,  9.4004e-01]],\n",
       " \n",
       "          [[ 5.9912e-01,  6.0696e-01,  2.8365e-01,  ...,  2.3281e+00,\n",
       "             2.3286e+00,  2.3290e+00],\n",
       "           [ 5.9777e-01,  6.0982e-01,  2.9071e-01,  ...,  2.3292e+00,\n",
       "             2.3295e+00,  2.3299e+00],\n",
       "           [ 5.6157e-01,  5.7782e-01,  2.6292e-01,  ...,  2.3303e+00,\n",
       "             2.3305e+00,  2.3307e+00],\n",
       "           ...,\n",
       "           [ 9.5980e-01,  8.5488e-01,  8.1967e-01,  ...,  1.5733e+00,\n",
       "             1.5743e+00,  1.8891e+00],\n",
       "           [ 9.5634e-01,  8.3460e-01,  5.9085e-01,  ...,  1.8754e+00,\n",
       "             1.8236e+00,  1.9287e+00],\n",
       "           [ 8.1344e-01,  9.3632e-01,  7.1061e-01,  ...,  1.9858e+00,\n",
       "             1.8986e+00,  1.8811e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 8.8872e-01,  8.5960e-01,  4.3661e-01,  ...,  1.0766e+00,\n",
       "             1.0777e+00,  1.0787e+00],\n",
       "           [ 8.1146e-01,  8.3286e-01,  4.0901e-01,  ...,  1.0563e+00,\n",
       "             1.0572e+00,  1.0581e+00],\n",
       "           [ 7.5131e-01,  8.0611e-01,  4.1566e-01,  ...,  1.0361e+00,\n",
       "             1.0368e+00,  1.0374e+00],\n",
       "           ...,\n",
       "           [ 9.9050e-01,  6.7119e-01,  4.5463e-01,  ...,  1.2255e+00,\n",
       "             1.1768e+00,  1.1282e+00],\n",
       "           [ 8.7497e-01,  7.5978e-01,  5.9321e-01,  ...,  1.3138e+00,\n",
       "             1.2104e+00,  1.1412e+00],\n",
       "           [ 7.5944e-01,  8.6549e-01,  8.1741e-01,  ...,  1.4535e+00,\n",
       "             1.3981e+00,  1.3255e+00]],\n",
       " \n",
       "          [[ 5.2445e-01,  5.1635e-01,  4.2072e-01,  ...,  6.8488e-01,\n",
       "             6.8491e-01,  6.8494e-01],\n",
       "           [ 4.9055e-01,  5.3055e-01,  4.3049e-01,  ...,  6.8500e-01,\n",
       "             6.8506e-01,  6.8512e-01],\n",
       "           [ 4.9167e-01,  5.6226e-01,  4.9279e-01,  ...,  6.8512e-01,\n",
       "             6.8521e-01,  6.8529e-01],\n",
       "           ...,\n",
       "           [ 9.1083e-01,  5.9609e-01,  5.9647e-01,  ...,  8.8041e-01,\n",
       "             8.6035e-01,  8.4028e-01],\n",
       "           [ 7.8865e-01,  6.8455e-01,  7.3802e-01,  ...,  9.8245e-01,\n",
       "             9.1004e-01,  8.7265e-01],\n",
       "           [ 6.6646e-01,  7.9052e-01,  9.6710e-01,  ...,  1.1370e+00,\n",
       "             1.1173e+00,  1.0801e+00]],\n",
       " \n",
       "          [[ 6.6884e-01,  6.2439e-01,  3.0108e-01,  ...,  2.3281e+00,\n",
       "             2.3286e+00,  2.3290e+00],\n",
       "           [ 6.1520e-01,  6.2725e-01,  3.0814e-01,  ...,  2.3292e+00,\n",
       "             2.3295e+00,  2.3299e+00],\n",
       "           [ 5.4414e-01,  5.9525e-01,  3.1521e-01,  ...,  2.3303e+00,\n",
       "             2.3305e+00,  2.3307e+00],\n",
       "           ...,\n",
       "           [ 1.0644e+00,  7.6773e-01,  7.1510e-01,  ...,  1.7301e+00,\n",
       "             1.7138e+00,  1.6974e+00],\n",
       "           [ 9.3891e-01,  8.5203e-01,  8.5229e-01,  ...,  1.8406e+00,\n",
       "             1.7713e+00,  1.7369e+00],\n",
       "           [ 8.1344e-01,  9.5375e-01,  1.0766e+00,  ...,  2.0033e+00,\n",
       "             1.9857e+00,  1.9508e+00]]]], device='cuda:0', grad_fn=<CopySlices>),\n",
       " 'imgs_aug': tensor([[[[ 6.8952e-01,  8.0806e-01,  4.2998e-01,  ...,  1.0447e+00,\n",
       "             1.0626e+00,  1.0634e+00],\n",
       "           [ 6.5004e-01,  7.8573e-01,  4.0769e-01,  ...,  1.0283e+00,\n",
       "             1.0460e+00,  1.0466e+00],\n",
       "           [ 6.6194e-01,  8.1479e-01,  3.8539e-01,  ...,  1.0119e+00,\n",
       "             1.0465e+00,  1.0469e+00],\n",
       "           ...,\n",
       "           [ 7.2434e-01,  7.6788e-01,  6.5729e-01,  ...,  9.1906e-01,\n",
       "             1.1087e+00,  1.0415e+00],\n",
       "           [ 7.4281e-01,  8.1964e-01,  7.7660e-01,  ...,  8.7811e-01,\n",
       "             1.0807e+00,  1.0949e+00],\n",
       "           [ 7.7840e-01,  8.2003e-01,  8.1029e-01,  ...,  8.2004e-01,\n",
       "             1.0527e+00,  1.0284e+00]],\n",
       " \n",
       "          [[ 3.5753e-01,  5.0745e-01,  4.6480e-01,  ...,  6.8444e-01,\n",
       "             6.6697e-01,  6.6702e-01],\n",
       "           [ 3.5840e-01,  5.2149e-01,  4.7450e-01,  ...,  6.8452e-01,\n",
       "             6.6708e-01,  6.6714e-01],\n",
       "           [ 4.1179e-01,  5.8805e-01,  4.8420e-01,  ...,  6.8460e-01,\n",
       "             6.8469e-01,  6.8478e-01],\n",
       "           ...,\n",
       "           [ 7.9268e-01,  8.4403e-01,  8.2534e-01,  ...,  6.5710e-01,\n",
       "             8.7096e-01,  8.2221e-01],\n",
       "           [ 6.3718e-01,  7.2396e-01,  9.5080e-01,  ...,  6.1570e-01,\n",
       "             8.4581e-01,  8.8334e-01],\n",
       "           [ 6.7426e-01,  7.2645e-01,  9.8872e-01,  ...,  5.5680e-01,\n",
       "             8.2067e-01,  8.2193e-01]],\n",
       " \n",
       "          [[ 4.4088e-01,  5.5057e-01,  2.2454e-01,  ...,  2.3112e+00,\n",
       "             2.3114e+00,  2.3117e+00],\n",
       "           [ 4.2313e-01,  5.5599e-01,  2.3570e-01,  ...,  2.3122e+00,\n",
       "             2.3124e+00,  2.3125e+00],\n",
       "           [ 4.5767e-01,  6.1370e-01,  2.4686e-01,  ...,  2.3133e+00,\n",
       "             2.3308e+00,  2.3308e+00],\n",
       "           ...,\n",
       "           [ 8.8805e-01,  9.5895e-01,  9.7756e-01,  ...,  1.5383e+00,\n",
       "             1.7709e+00,  1.7421e+00],\n",
       "           [ 7.9797e-01,  9.0483e-01,  1.0640e+00,  ...,  1.5130e+00,\n",
       "             1.7627e+00,  1.8208e+00],\n",
       "           [ 8.2989e-01,  9.0299e-01,  1.0981e+00,  ...,  1.4702e+00,\n",
       "             1.7545e+00,  1.7774e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 6.8952e-01,  8.0806e-01,  4.2998e-01,  ...,  1.0447e+00,\n",
       "             1.0626e+00,  1.0634e+00],\n",
       "           [ 6.5004e-01,  7.8573e-01,  4.0769e-01,  ...,  1.0283e+00,\n",
       "             1.0460e+00,  1.0466e+00],\n",
       "           [ 6.6194e-01,  8.1479e-01,  3.8539e-01,  ...,  1.0119e+00,\n",
       "             1.0465e+00,  1.0469e+00],\n",
       "           ...,\n",
       "           [ 6.2160e-01,  6.4800e-01,  4.6892e-01,  ...,  4.9094e-01,\n",
       "             1.3261e-01,  1.6815e-01],\n",
       "           [ 6.7431e-01,  6.1414e-01,  5.1973e-01,  ...,  6.2124e-01,\n",
       "             3.2721e-01,  2.0443e-01],\n",
       "           [ 8.8115e-01,  5.9741e-01,  5.7054e-01,  ...,  6.6592e-01,\n",
       "             4.5331e-01,  1.8933e-01]],\n",
       " \n",
       "          [[ 3.5753e-01,  5.0745e-01,  4.6480e-01,  ...,  6.8444e-01,\n",
       "             6.6697e-01,  6.6702e-01],\n",
       "           [ 3.5840e-01,  5.2149e-01,  4.7450e-01,  ...,  6.8452e-01,\n",
       "             6.6708e-01,  6.6714e-01],\n",
       "           [ 4.1179e-01,  5.8805e-01,  4.8420e-01,  ...,  6.8460e-01,\n",
       "             6.8469e-01,  6.8478e-01],\n",
       "           ...,\n",
       "           [ 6.8764e-01,  7.2148e-01,  8.0784e-01,  ...,  2.1943e-01,\n",
       "            -1.2694e-01, -7.0650e-02],\n",
       "           [ 7.4222e-01,  6.8895e-01,  8.1075e-01,  ...,  3.5310e-01,\n",
       "             7.5503e-02, -2.7021e-02],\n",
       "           [ 9.5437e-01,  6.7393e-01,  8.6618e-01,  ...,  3.9923e-01,\n",
       "             2.0792e-01, -3.5913e-02]],\n",
       " \n",
       "          [[ 4.4088e-01,  5.5057e-01,  2.2454e-01,  ...,  2.3112e+00,\n",
       "             2.3114e+00,  2.3117e+00],\n",
       "           [ 4.2313e-01,  5.5599e-01,  2.3570e-01,  ...,  2.3122e+00,\n",
       "             2.3124e+00,  2.3125e+00],\n",
       "           [ 4.5767e-01,  6.1370e-01,  2.4686e-01,  ...,  2.3133e+00,\n",
       "             2.3308e+00,  2.3308e+00],\n",
       "           ...,\n",
       "           [ 8.1834e-01,  8.7181e-01,  8.5556e-01,  ...,  1.0677e+00,\n",
       "             7.4261e-01,  8.1838e-01],\n",
       "           [ 8.6769e-01,  8.3511e-01,  9.0711e-01,  ...,  1.2167e+00,\n",
       "             9.6099e-01,  8.7959e-01],\n",
       "           [ 1.0739e+00,  8.1585e-01,  9.5866e-01,  ...,  1.2785e+00,\n",
       "             1.1096e+00,  8.8851e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 6.8952e-01,  8.0806e-01,  4.2998e-01,  ...,  1.0447e+00,\n",
       "             1.0626e+00,  1.0634e+00],\n",
       "           [ 6.5004e-01,  7.8573e-01,  4.0769e-01,  ...,  1.0283e+00,\n",
       "             1.0460e+00,  1.0466e+00],\n",
       "           [ 6.6194e-01,  8.1479e-01,  3.8539e-01,  ...,  1.0119e+00,\n",
       "             1.0294e+00,  1.0298e+00],\n",
       "           ...,\n",
       "           [ 6.0447e-01,  6.6513e-01,  6.4016e-01,  ...,  5.5944e-01,\n",
       "             2.6961e-01,  4.8272e-02],\n",
       "           [ 7.0856e-01,  7.1689e-01,  6.5673e-01,  ...,  2.6162e-01,\n",
       "             2.4158e-01,  2.0443e-01],\n",
       "           [ 7.2703e-01,  7.3441e-01,  6.5616e-01,  ...,  1.5175e-02,\n",
       "             2.5191e-02,  2.2358e-01]],\n",
       " \n",
       "          [[ 3.5753e-01,  5.0745e-01,  4.6480e-01,  ...,  6.8444e-01,\n",
       "             6.6697e-01,  6.6702e-01],\n",
       "           [ 3.5840e-01,  5.2149e-01,  4.7450e-01,  ...,  6.8452e-01,\n",
       "             6.6708e-01,  6.6714e-01],\n",
       "           [ 4.1179e-01,  5.8805e-01,  4.8420e-01,  ...,  6.8460e-01,\n",
       "             6.6718e-01,  6.6727e-01],\n",
       "           ...,\n",
       "           [ 7.0515e-01,  7.7400e-01,  9.8291e-01,  ...,  2.8945e-01,\n",
       "             1.3113e-02, -1.9320e-01],\n",
       "           [ 8.1225e-01,  8.2901e-01,  1.0033e+00,  ..., -1.4550e-02,\n",
       "            -1.2032e-02, -2.7021e-02],\n",
       "           [ 8.3182e-01,  8.4900e-01,  1.0062e+00,  ..., -2.6603e-01,\n",
       "            -2.2975e-01, -8.9911e-04]],\n",
       " \n",
       "          [[ 4.4088e-01,  5.5057e-01,  2.2454e-01,  ...,  2.3112e+00,\n",
       "             2.3114e+00,  2.3117e+00],\n",
       "           [ 4.2313e-01,  5.5599e-01,  2.3570e-01,  ...,  2.3122e+00,\n",
       "             2.3124e+00,  2.3125e+00],\n",
       "           [ 4.5767e-01,  6.1370e-01,  2.4686e-01,  ...,  2.3133e+00,\n",
       "             2.3133e+00,  2.3134e+00],\n",
       "           ...,\n",
       "           [ 8.8805e-01,  9.7638e-01,  1.1170e+00,  ...,  1.1374e+00,\n",
       "             8.8204e-01,  6.9638e-01],\n",
       "           [ 9.8969e-01,  1.0268e+00,  1.1337e+00,  ...,  8.5066e-01,\n",
       "             8.7384e-01,  8.7959e-01],\n",
       "           [ 1.0042e+00,  1.0424e+00,  1.1330e+00,  ...,  6.1618e-01,\n",
       "             6.7392e-01,  9.2337e-01]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 7.3169e-01,  7.8392e-01,  3.7379e-01,  ...,  1.0684e+00,\n",
       "             1.0705e+00,  1.0726e+00],\n",
       "           [ 7.4260e-01,  7.4319e-01,  3.3278e-01,  ...,  1.0404e+00,\n",
       "             1.0422e+00,  1.0440e+00],\n",
       "           [ 7.5351e-01,  7.3670e-01,  3.0890e-01,  ...,  1.0125e+00,\n",
       "             1.0140e+00,  1.0155e+00],\n",
       "           ...,\n",
       "           [ 8.0826e-01,  7.6514e-01,  7.2202e-01,  ...,  8.7771e-01,\n",
       "             8.6029e-01,  8.4288e-01],\n",
       "           [ 7.2622e-01,  7.5060e-01,  6.8935e-01,  ...,  7.6658e-01,\n",
       "             7.4519e-01,  7.2380e-01],\n",
       "           [ 6.9556e-01,  7.3606e-01,  6.2243e-01,  ...,  7.5819e-01,\n",
       "             6.9858e-01,  6.5609e-01]],\n",
       " \n",
       "          [[ 4.0165e-01,  4.8262e-01,  3.8852e-01,  ...,  6.8562e-01,\n",
       "             6.8570e-01,  6.8578e-01],\n",
       "           [ 4.5569e-01,  4.7956e-01,  3.8088e-01,  ...,  6.8587e-01,\n",
       "             6.8598e-01,  6.8609e-01],\n",
       "           [ 4.9223e-01,  4.9401e-01,  3.9074e-01,  ...,  6.8612e-01,\n",
       "             6.8626e-01,  6.8640e-01],\n",
       "           ...,\n",
       "           [ 7.2682e-01,  6.9066e-01,  8.6459e-01,  ...,  5.1666e-01,\n",
       "             5.2666e-01,  5.3667e-01],\n",
       "           [ 6.3990e-01,  6.7423e-01,  8.3111e-01,  ...,  4.0751e-01,\n",
       "             4.1755e-01,  4.2760e-01],\n",
       "           [ 6.0551e-01,  6.5780e-01,  7.6261e-01,  ...,  4.0340e-01,\n",
       "             3.7847e-01,  3.7105e-01]],\n",
       " \n",
       "          [[ 5.6085e-01,  6.0109e-01,  2.4046e-01,  ...,  2.3313e+00,\n",
       "             2.3314e+00,  2.3315e+00],\n",
       "           [ 5.9523e-01,  5.8873e-01,  2.3364e-01,  ...,  2.3320e+00,\n",
       "             2.3321e+00,  2.3321e+00],\n",
       "           [ 5.7732e-01,  5.5894e-01,  1.9197e-01,  ...,  2.3328e+00,\n",
       "             2.3328e+00,  2.3328e+00],\n",
       "           ...,\n",
       "           [ 7.7506e-01,  7.4973e-01,  8.6384e-01,  ...,  1.5186e+00,\n",
       "             1.5383e+00,  1.5580e+00],\n",
       "           [ 6.9000e-01,  7.3454e-01,  8.3138e-01,  ...,  1.4188e+00,\n",
       "             1.4380e+00,  1.4573e+00],\n",
       "           [ 6.5722e-01,  7.1936e-01,  7.6407e-01,  ...,  1.4235e+00,\n",
       "             1.4075e+00,  1.4088e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 8.2023e-01,  8.4248e-01,  4.1949e-01,  ...,  1.0766e+00,\n",
       "             1.0777e+00,  1.0787e+00],\n",
       "           [ 7.9433e-01,  8.1573e-01,  3.9189e-01,  ...,  1.0563e+00,\n",
       "             1.0572e+00,  1.0581e+00],\n",
       "           [ 7.6844e-01,  7.8898e-01,  3.6428e-01,  ...,  1.0361e+00,\n",
       "             1.0368e+00,  1.0374e+00],\n",
       "           ...,\n",
       "           [ 8.8775e-01,  7.5681e-01,  5.5738e-01,  ...,  9.3437e-01,\n",
       "             9.5422e-01,  1.2309e+00],\n",
       "           [ 8.9210e-01,  7.4265e-01,  3.3634e-01,  ...,  1.2111e+00,\n",
       "             1.1761e+00,  1.2440e+00],\n",
       "           [ 7.5944e-01,  8.4836e-01,  4.5779e-01,  ...,  1.2994e+00,\n",
       "             1.2268e+00,  1.1714e+00]],\n",
       " \n",
       "          [[ 4.5442e-01,  4.9884e-01,  4.0321e-01,  ...,  6.8488e-01,\n",
       "             6.8491e-01,  6.8494e-01],\n",
       "           [ 4.7305e-01,  5.1304e-01,  4.1299e-01,  ...,  6.8500e-01,\n",
       "             6.8506e-01,  6.8512e-01],\n",
       "           [ 5.0917e-01,  5.4475e-01,  4.4027e-01,  ...,  6.8512e-01,\n",
       "             6.8521e-01,  6.8529e-01],\n",
       "           ...,\n",
       "           [ 8.0579e-01,  6.8362e-01,  7.0151e-01,  ...,  6.0030e-01,\n",
       "             6.5026e-01,  9.6283e-01],\n",
       "           [ 8.0616e-01,  6.6704e-01,  4.7541e-01,  ...,  8.9491e-01,\n",
       "             8.9254e-01,  9.9520e-01],\n",
       "           [ 6.6646e-01,  7.7302e-01,  5.9946e-01,  ...,  9.9695e-01,\n",
       "             9.5974e-01,  9.4004e-01]],\n",
       " \n",
       "          [[ 5.9912e-01,  6.0696e-01,  2.8365e-01,  ...,  2.3281e+00,\n",
       "             2.3286e+00,  2.3290e+00],\n",
       "           [ 5.9777e-01,  6.0982e-01,  2.9071e-01,  ...,  2.3292e+00,\n",
       "             2.3295e+00,  2.3299e+00],\n",
       "           [ 5.6157e-01,  5.7782e-01,  2.6292e-01,  ...,  2.3303e+00,\n",
       "             2.3305e+00,  2.3307e+00],\n",
       "           ...,\n",
       "           [ 9.5980e-01,  8.5488e-01,  8.1967e-01,  ...,  1.5733e+00,\n",
       "             1.5743e+00,  1.8891e+00],\n",
       "           [ 9.5634e-01,  8.3460e-01,  5.9085e-01,  ...,  1.8754e+00,\n",
       "             1.8236e+00,  1.9287e+00],\n",
       "           [ 8.1344e-01,  9.3632e-01,  7.1061e-01,  ...,  1.9858e+00,\n",
       "             1.8986e+00,  1.8811e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 8.8872e-01,  8.5960e-01,  4.3661e-01,  ...,  1.0766e+00,\n",
       "             1.0777e+00,  1.0787e+00],\n",
       "           [ 8.1146e-01,  8.3286e-01,  4.0901e-01,  ...,  1.0563e+00,\n",
       "             1.0572e+00,  1.0581e+00],\n",
       "           [ 7.5131e-01,  8.0611e-01,  4.1566e-01,  ...,  1.0361e+00,\n",
       "             1.0368e+00,  1.0374e+00],\n",
       "           ...,\n",
       "           [ 9.9050e-01,  6.7119e-01,  4.5463e-01,  ...,  1.2255e+00,\n",
       "             1.1768e+00,  1.1282e+00],\n",
       "           [ 8.7497e-01,  7.5978e-01,  5.9321e-01,  ...,  1.3138e+00,\n",
       "             1.2104e+00,  1.1412e+00],\n",
       "           [ 7.5944e-01,  8.6549e-01,  8.1741e-01,  ...,  1.4535e+00,\n",
       "             1.3981e+00,  1.3255e+00]],\n",
       " \n",
       "          [[ 5.2445e-01,  5.1635e-01,  4.2072e-01,  ...,  6.8488e-01,\n",
       "             6.8491e-01,  6.8494e-01],\n",
       "           [ 4.9055e-01,  5.3055e-01,  4.3049e-01,  ...,  6.8500e-01,\n",
       "             6.8506e-01,  6.8512e-01],\n",
       "           [ 4.9167e-01,  5.6226e-01,  4.9279e-01,  ...,  6.8512e-01,\n",
       "             6.8521e-01,  6.8529e-01],\n",
       "           ...,\n",
       "           [ 9.1083e-01,  5.9609e-01,  5.9647e-01,  ...,  8.8041e-01,\n",
       "             8.6035e-01,  8.4028e-01],\n",
       "           [ 7.8865e-01,  6.8455e-01,  7.3802e-01,  ...,  9.8245e-01,\n",
       "             9.1004e-01,  8.7265e-01],\n",
       "           [ 6.6646e-01,  7.9052e-01,  9.6710e-01,  ...,  1.1370e+00,\n",
       "             1.1173e+00,  1.0801e+00]],\n",
       " \n",
       "          [[ 6.6884e-01,  6.2439e-01,  3.0108e-01,  ...,  2.3281e+00,\n",
       "             2.3286e+00,  2.3290e+00],\n",
       "           [ 6.1520e-01,  6.2725e-01,  3.0814e-01,  ...,  2.3292e+00,\n",
       "             2.3295e+00,  2.3299e+00],\n",
       "           [ 5.4414e-01,  5.9525e-01,  3.1521e-01,  ...,  2.3303e+00,\n",
       "             2.3305e+00,  2.3307e+00],\n",
       "           ...,\n",
       "           [ 1.0644e+00,  7.6773e-01,  7.1510e-01,  ...,  1.7301e+00,\n",
       "             1.7138e+00,  1.6974e+00],\n",
       "           [ 9.3891e-01,  8.5203e-01,  8.5229e-01,  ...,  1.8406e+00,\n",
       "             1.7713e+00,  1.7369e+00],\n",
       "           [ 8.1344e-01,  9.5375e-01,  1.0766e+00,  ...,  2.0033e+00,\n",
       "             1.9857e+00,  1.9508e+00]]]], device='cuda:0', grad_fn=<CopySlices>),\n",
       " 'preds': tensor([False,  True,  True,  True, False,  True,  True, False, False, False,\n",
       "          True, False,  True, False, False,  True,  True, False, False, False,\n",
       "          True, False, False, False,  True, False,  True,  True,  True,  True,\n",
       "          True, False], device='cuda:0'),\n",
       " 'selected_aug': 'Identity()'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 3, 1920, 1080])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() received an invalid combination of arguments - got (int, int, tuple), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int high, tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int low, int high, tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m msgs \u001b[38;5;241m=\u001b[39m \u001b[43mwam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_random_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# b x k\u001b[39;00m\n",
      "File \u001b[0;32m~/work/code/videoseal/videoseal/videoseal/models/wam.py:57\u001b[0m, in \u001b[0;36mWam.get_random_msg\u001b[0;34m(self, bsz, nb_repetitions)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_random_msg\u001b[39m(\u001b[38;5;28mself\u001b[39m, bsz: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, nb_repetitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_random_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbsz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_repetitions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/code/videoseal/videoseal/videoseal/models/embedder.py:101\u001b[0m, in \u001b[0;36mUnetEmbedder.get_random_msg\u001b[0;34m(self, bsz, nb_repetitions)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_random_msg\u001b[39m(\u001b[38;5;28mself\u001b[39m, bsz: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, nb_repetitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmsg_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_random_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbsz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_repetitions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/code/videoseal/videoseal/videoseal/modules/msg_processor.py:54\u001b[0m, in \u001b[0;36mMsgProcessor.get_random_msg\u001b[0;34m(self, bsz, nb_repetitions)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m aux\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, nb_repetitions, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(bsz, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnbits)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbsz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnbits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsg_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgau\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m     gauss_vecs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(bsz, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnbits)\n",
      "\u001b[0;31mTypeError\u001b[0m: randint() received an invalid combination of arguments - got (int, int, tuple), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int high, tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int low, int high, tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stablesign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
