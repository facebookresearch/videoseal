{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/hadyelsahar/work/code/videoseal/videoseal\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/hadyelsahar/anaconda3/envs/videoseal/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from videoseal.utils.display import save_vid\n",
    "from videoseal.utils import Timer\n",
    "from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy\n",
    "from videoseal.data.datasets import VideoDataset\n",
    "from videoseal.augmentation import Identity, H264\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-sleepwake-resume/_attenuation=jnd_1_1/checkpoint.pth with message: _IncompatibleKeys(missing_keys=[], unexpected_keys=['attenuation.conv_x.weight', 'attenuation.conv_y.weight', 'attenuation.conv_lum.weight', 'blender.attenuation.conv_x.weight', 'blender.attenuation.conv_y.weight', 'blender.attenuation.conv_lum.weight', 'blender.attentuation.conv_x.weight', 'blender.attentuation.conv_y.weight', 'blender.attentuation.conv_lum.weight'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos for 1111-finetuned:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading video assets/videos/metamoviegen/metamoviegen3.mp4 - took 9.45s\n",
      "embedding watermark  - took 8.87s\n",
      "saving videos - took 35.36s\n",
      "compressing and detecting watermarks\n",
      "CRF=23 Bit Accuracy: 0.788 - detection took 1.79s\n",
      "CRF=40 Bit Accuracy: 0.788 - detection took 1.74s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos for 1111-finetuned:  33%|███▎      | 1/3 [02:13<04:27, 133.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading video assets/videos/metamoviegen/metamoviegen2.mp4 - took 9.63s\n",
      "embedding watermark  - took 8.90s\n",
      "saving videos - took 37.62s\n",
      "compressing and detecting watermarks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Directory containing videos\n",
    "video_dir = \"assets/videos/metamoviegen\"\n",
    "\n",
    "# Example usage\n",
    "ckpts = {\n",
    "    # \"hidden\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.0_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=hidden/checkpoint.pth',\n",
    "    # \"unet\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.5_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=unet_small2/checkpoint.pth',\n",
    "    # \"scaling_laws_smalldetector_tinyembedder\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1105-videoseal0.2-scalinglaws/_lambda_d=0.0_extractor_model=sam_small_embedder_model=0/checkpoint.pth\",\n",
    "    # \"scaling_laws_tinydetector_tinyembedder\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1105-videoseal0.2-scalinglaws/_lambda_d=0.0_extractor_model=sam_tiny_embedder_model=0/checkpoint.pth\",\n",
    "    # \"JND_fix_discloss\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1108-videoseal0.2-discloss-fix-removeunused-params/_attenuation=jnd_3_3_nbits=64_lambda_d=0.5_video_start=100/checkpoint.pth\",\n",
    "    # \"1111_discloss_sleepwake_highssim\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1109-videoseal0.2-discloss-fix-hing-sleepwake-4nodes/_scaling_w=0.1_lambda_i=0.25_disc_hinge_on_logits_fake=False_sleepwake=True_video_start=500/checkpoint.pth\"\n",
    "    \"1111-finetuned\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-sleepwake-resume/_attenuation=jnd_1_1/checkpoint.pth\"\n",
    "}\n",
    "\n",
    "fps = 24 // 1\n",
    "# frames_per_clip = fps * 3  # 3s\n",
    "# frame_step = 1\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "base_output_folder = \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/video_outputs\"\n",
    "# Iterate over all checkpoints\n",
    "for model_name, ckpt in ckpts.items():\n",
    "    wam = setup_model_from_checkpoint(ckpt)\n",
    "    wam.eval()\n",
    "    wam.to(device)\n",
    "\n",
    "    # Iterate over all video files in the directory\n",
    "    video_files = [f for f in os.listdir(video_dir) if f.endswith(\".mp4\")][1:]\n",
    "\n",
    "    for video_file in tqdm(video_files, desc=f\"Processing Videos for {model_name}\"):\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        base_name = os.path.splitext(video_file)[0]\n",
    "\n",
    "        # Load video (assuming a function `load_video` exists)\n",
    "        timer.start()\n",
    "        vid, mask = VideoDataset.load_full_video_decord(video_path)\n",
    "        print(f\"loading video {video_path} - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Watermark embedding\n",
    "        timer.start()\n",
    "        outputs = wam.embed(vid, is_video=True)\n",
    "        print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # compute diff\n",
    "        imgs = vid  # b c h w\n",
    "        imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "        msgs = outputs[\"msgs\"]  # b k\n",
    "        diff = imgs_w - imgs\n",
    "\n",
    "        # save\n",
    "        timer.start()\n",
    "        save_vid(imgs, f\"{base_output_folder}/{model_name}_{base_name}.mp4\", fps)\n",
    "        save_vid(imgs_w, f\"{base_output_folder}/{model_name}_{base_name}_wmed.mp4\", fps)\n",
    "        save_vid(diff, f\"{base_output_folder}/{model_name}_{base_name}_wm.mp4\", fps)\n",
    "\n",
    "        # Compute min and max values, reshape, and normalize\n",
    "        min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "        # Save the normalized video\n",
    "        save_vid(normalized_images, f\"{base_output_folder}/{model_name}_{base_name}_wm_normalized.mp4\", fps)\n",
    "        print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Augment video\n",
    "        print(f\"compressing and detecting watermarks\")\n",
    "        for crf in [23, 40]:\n",
    "            imgs_aug, _ = H264()(imgs_w, crf=crf)\n",
    "\n",
    "            # detect\n",
    "            timer.start()\n",
    "            outputs = wam.detect(imgs_aug, is_video=True)\n",
    "            preds = outputs[\"preds\"]\n",
    "            bit_preds = preds[:, 1:]  # b k ...\n",
    "            bit_accuracy_ = bit_accuracy(\n",
    "                bit_preds,\n",
    "                msgs\n",
    "            ).nanmean().item()\n",
    "            print(f\"CRF={crf} Bit Accuracy: {bit_accuracy_:.3f} - detection took {timer.stop():.2f}s\")\n",
    "\n",
    "        del vid, mask, outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "    # Free model from GPU\n",
    "    del wam\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videoseal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
