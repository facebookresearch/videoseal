{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/09-videoseal/baselines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from videoseal.utils.display import save_vid\n",
    "from videoseal.utils import Timer\n",
    "from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy, pvalue, capacity, psnr\n",
    "from videoseal.data.datasets import VideoDataset\n",
    "from videoseal.augmentation import Identity, H264, Crop\n",
    "from videoseal.modules.jnd import JND, JNDSimplified\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /large_experiments/meres/hadyelsahar/2024_logs/1120-videoseal0.4/_scaling_w=0.5_sleepwake=False_videowam_step_size=4_extractor_model=sam_tiny/checkpoint.pth with message: <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos for videoseal0.4:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading video /checkpoint/pfz/projects/videoseal/assets/videos/metamoviegen_3s/01.mp4 - took 2.27s\n",
      "embedding watermark  - took 1.49s\n",
      "PSNR: 44.291\n",
      "saving videos - took 12.12s\n",
      "compressing and detecting watermarks\n",
      "Original - Bit Accuracy: 0.938 - P-Value: 3.68e-14 - Capacity: 42.413 - took 0.35s\n",
      "H264 40 + Crop 0.8 - Bit Accuracy: 0.516 - P-Value: 4.50e-01 - Capacity: 0.045 - took 0.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos for videoseal0.4: 100%|██████████| 1/1 [00:32<00:00, 32.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Directory containing videos\n",
    "video_dir = \"/checkpoint/pfz/projects/videoseal/assets/videos/metamoviegen_3s\"\n",
    "base_output_folder = \"outputs\"\n",
    "if not os.path.exists(base_output_folder):\n",
    "    os.makedirs(base_output_folder)\n",
    "\n",
    "# Example usage\n",
    "ckpts = {\n",
    "    # \"hidden\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.0_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=hidden/checkpoint.pth',\n",
    "    # \"unet\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.5_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=unet_small2/checkpoint.pth',\n",
    "    # \"scaling_laws_smalldetector_tinyembedder\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1105-videoseal0.2-scalinglaws/_lambda_d=0.0_extractor_model=sam_small_embedder_model=0/checkpoint.pth\",\n",
    "    # \"scaling_laws_tinydetector_tinyembedder\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1105-videoseal0.2-scalinglaws/_lambda_d=0.0_extractor_model=sam_tiny_embedder_model=0/checkpoint.pth\",\n",
    "    # \"JND_fix_discloss\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1108-videoseal0.2-discloss-fix-removeunused-params/_attenuation=jnd_3_3_nbits=64_lambda_d=0.5_video_start=100/checkpoint.pth\",\n",
    "    # \"1111_discloss_sleepwake_highssim\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1109-videoseal0.2-discloss-fix-hing-sleepwake-4nodes/_scaling_w=0.1_lambda_i=0.25_disc_hinge_on_logits_fake=False_sleepwake=True_video_start=500/checkpoint.pth\"\n",
    "    # \"1111-finetuned\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-sleepwake-resume/_attenuation=jnd_1_1/checkpoint.pth\"\n",
    "    # \"1112-videoseal0.2\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-archsearch-4nodes/_attenuation=None_nbits=64_finetune_detector_start=1000_embedder_model=unet_small2_quant/checkpoint.pth\",\n",
    "    # \"1118-yuv-400\":\"/checkpoint/pfz/2024_logs/1118_vseal_long_sab/_scheduler=0_optimizer=adopt,lr=1e-5/checkpoint400.pth\",\n",
    "    # \"1118-yuv-800\":\"/checkpoint/pfz/2024_logs/1118_vseal_long_sab/_scheduler=1_optimizer=AdamW,lr=1e-5/checkpoint.pth\",\n",
    "    # \"trustmark\": \"baseline/trustmark\",\n",
    "    # \"videoseal0.2b\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-archsearch-4nodes/_attenuation=None_nbits=64_finetune_detector_start=800_embedder_model=unet_small2_quant/checkpoint.pth\",\n",
    "    # \"videoseal0.2a\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1109-videoseal0.2-discloss-fix-hing-sleepwake-4nodes/_scaling_w=0.5_lambda_i=0.5_disc_hinge_on_logits_fake=True_sleepwake=False_video_start=500/checkpoint.pth\",\n",
    "    \"videoseal0.4\": \"/large_experiments/meres/hadyelsahar/2024_logs/1120-videoseal0.4/_scaling_w=0.5_sleepwake=False_videowam_step_size=4_extractor_model=sam_tiny/checkpoint.pth\",\n",
    "    # \"wam\": \"baseline/wam\",\n",
    "    # \"mbrs\": \"baseline/mbrs\",\n",
    "}\n",
    "\n",
    "fps = 24 // 1\n",
    "# frames_per_clip = fps * 3  # 3s\n",
    "# frame_step = 1\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "\n",
    "# Iterate over all checkpoints\n",
    "for model_name, ckpt in ckpts.items():\n",
    "    wam = setup_model_from_checkpoint(ckpt)\n",
    "    wam.eval()\n",
    "    wam.to(device)\n",
    "\n",
    "    # scaling_w = 0.3\n",
    "    # attenuation = JND(in_channels=1, out_channels=3, blue=True)\n",
    "    # wam.attenuation = attenuation\n",
    "    # wam.blender.scaling_w = scaling_w\n",
    "\n",
    "    scaling_w = 1.0\n",
    "    attenuation = JNDSimplified(in_channels=1, out_channels=3, blue=True)\n",
    "    wam.attenuation = attenuation\n",
    "    wam.blender.scaling_w = scaling_w\n",
    "\n",
    "    wam.chunk_size = 200\n",
    "    wam.step_size = 16\n",
    "\n",
    "    # Iterate over all video files in the directory\n",
    "    video_files = [f for f in os.listdir(video_dir) if f.endswith(\".mp4\")][:1]\n",
    "\n",
    "    for video_file in tqdm(video_files, desc=f\"Processing Videos for {model_name}\"):\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        base_name = os.path.splitext(video_file)[0]\n",
    "\n",
    "        # Load video (assuming a function `load_video` exists)\n",
    "        timer.start()\n",
    "        vid, mask = VideoDataset.load_full_video_decord(video_path)\n",
    "        print(f\"loading video {video_path} - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Watermark embedding\n",
    "        timer.start()\n",
    "        outputs = wam.embed_lowres_attenuation(vid, is_video=True)\n",
    "        # outputs = wam.embed(vid, is_video=True)\n",
    "        print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # compute diff\n",
    "        imgs = vid  # b c h w\n",
    "        imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "        msgs = outputs[\"msgs\"]  # b k\n",
    "        diff = imgs_w - imgs\n",
    "\n",
    "        # save\n",
    "        timer.start()\n",
    "        save_vid(imgs, f\"{base_output_folder}/{model_name}_{base_name}_ori.mp4\", fps)\n",
    "        save_vid(imgs_w, f\"{base_output_folder}/{model_name}_{base_name}_wm.mp4\", fps)\n",
    "        save_vid(10*diff.abs(), f\"{base_output_folder}/{model_name}_{base_name}_diff.mp4\", fps)\n",
    "\n",
    "        # psnr\n",
    "        psnr_score = psnr(imgs, imgs_w, is_video=True).mean().item()\n",
    "        print(f\"PSNR: {psnr_score:.3f}\")\n",
    "\n",
    "        # Compute min and max values, reshape, and normalize\n",
    "        min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "        # Save the normalized video\n",
    "        save_vid(normalized_images, f\"{base_output_folder}/{model_name}_{base_name}_wm_normalized.mp4\", fps)\n",
    "        print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Augment video\n",
    "        print(f\"compressing and detecting watermarks\")\n",
    "        # for crf in [-1, 23, 40, 60]:\n",
    "        #     if crf == -1:\n",
    "        #         imgs_aug = imgs_w\n",
    "        #     else:\n",
    "        #         imgs_aug, _ = H264()(imgs_w, crf=crf)\n",
    "        for ii in range(2):\n",
    "            if ii == 0:\n",
    "                imgs_aug = imgs_w\n",
    "                label = \"Original\"\n",
    "            if ii == 1: \n",
    "                imgs_aug, _ = H264()(imgs_w, crf=40)\n",
    "                imgs_aug, _ = Crop()(imgs_aug, size=0.75)\n",
    "                label = \"H264 40 + Crop 0.8\"\n",
    "\n",
    "            save_vid(imgs_aug, f\"{base_output_folder}/{model_name}_{base_name}_wm_{label.lower().replace(\" \", \"_\").replace(\".\", \"\")}.mp4\", fps)\n",
    "            timer.start()\n",
    "            aggregate = True\n",
    "            if not aggregate:\n",
    "                outputs = wam.detect(imgs_aug, is_video=True)\n",
    "                preds = outputs[\"preds\"]\n",
    "                bit_preds = preds[:, 1:]  # b k ...\n",
    "                bit_accuracy_ = bit_accuracy(\n",
    "                    bit_preds,\n",
    "                    msgs\n",
    "                ).nanmean().item()\n",
    "                print(f\"{label} - Bit Accuracy: {bit_accuracy_:.3f} - took {timer.stop():.2f}s\")\n",
    "            else:\n",
    "                bit_preds = wam.detect_and_aggregate(imgs_aug)\n",
    "                bit_accuracy_ = bit_accuracy(\n",
    "                    bit_preds,\n",
    "                    msgs[:1]\n",
    "                ).nanmean().item()\n",
    "                pvalue_ = pvalue(\n",
    "                    bit_preds,\n",
    "                    msgs[:1]\n",
    "                ).nanmean().item()\n",
    "                capacity_ = capacity(\n",
    "                    bit_preds,\n",
    "                    msgs[:1]\n",
    "                ).nanmean().item()\n",
    "                print(f\"{label} - Bit Accuracy: {bit_accuracy_:.3f} - P-Value: {pvalue_:0.2e} - Capacity: {capacity_:.3f} - took {timer.stop():.2f}s\")\n",
    "\n",
    "        del vid, outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "    # # Free model from GPU\n",
    "    # del wam\n",
    "    # torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = wam.detect(imgs_aug, is_video=True)\n",
    "outputs[\"preds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /large_experiments/meres/hadyelsahar/2024_logs/1120-videoseal0.4/_scaling_w=0.5_sleepwake=False_videowam_step_size=4_extractor_model=sam_tiny/checkpoint.pth with message: <All keys matched successfully>\n",
      "CRF=60 - Bit Accuracy: 1.000 - P-Value: 5.42e-20 - Capacity: 64.000 - took 0.82s\n"
     ]
    }
   ],
   "source": [
    "wam = setup_model_from_checkpoint(ckpt)\n",
    "wam.eval()\n",
    "wam.to(device)\n",
    "\n",
    "video_path = \"/private/home/pfz/09-videoseal/baselines/outputs/videoseal0.4_01_wm_crop_08_h264_40.mp4\"\n",
    "vid, mask = VideoDataset.load_full_video_decord(video_path)\n",
    "\n",
    "timer.start()\n",
    "bit_preds = wam.detect_and_aggregate(imgs_aug)\n",
    "bit_accuracy_ = bit_accuracy(\n",
    "    bit_preds,\n",
    "    msgs[:1]\n",
    ").nanmean().item()\n",
    "pvalue_ = pvalue(\n",
    "    bit_preds,\n",
    "    msgs[:1]\n",
    ").nanmean().item()\n",
    "capacity_ = capacity(\n",
    "    bit_preds,\n",
    "    msgs[:1]\n",
    ").nanmean().item()\n",
    "print(f\"CRF={crf} - Bit Accuracy: {bit_accuracy_:.3f} - P-Value: {pvalue_:0.2e} - Capacity: {capacity_:.3f} - took {timer.stop():.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1,  ..., 0, 1, 1],\n",
       "        [1, 0, 1,  ..., 0, 1, 1],\n",
       "        [1, 0, 1,  ..., 0, 1, 1],\n",
       "        ...,\n",
       "        [1, 0, 1,  ..., 0, 1, 1],\n",
       "        [1, 0, 1,  ..., 0, 1, 1],\n",
       "        [1, 0, 1,  ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False,  True,  True, False,  True,  True, False, False,  True,\n",
       "         False,  True, False,  True,  True, False,  True, False,  True,  True,\n",
       "         False, False,  True, False, False,  True, False,  True,  True,  True,\n",
       "         False,  True, False, False,  True, False, False,  True, False,  True,\n",
       "         False,  True,  True, False, False, False,  True, False,  True,  True,\n",
       "         False, False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "         False, False,  True,  True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bit_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
