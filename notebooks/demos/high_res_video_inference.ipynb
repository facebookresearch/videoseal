{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/09-videoseal/baselines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from videoseal.utils.display import save_vid\n",
    "from videoseal.utils import Timer\n",
    "from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy, pvalue, capacity, psnr\n",
    "from videoseal.data.datasets import VideoDataset\n",
    "from videoseal.augmentation import Identity, H264, Crop\n",
    "from videoseal.modules.jnd import JND, JNDSimplified\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos for wam:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading video /checkpoint/pfz/projects/videoseal/assets/videos/metamoviegen_3s/01.mp4 - took 2.23s\n",
      "embedding watermark  - took 12.89s\n",
      "PSNR: 37.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos for wam:   0%|          | 0/1 [00:26<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m normalized_images \u001b[38;5;241m=\u001b[39m (diff \u001b[38;5;241m-\u001b[39m min_vals) \u001b[38;5;241m/\u001b[39m (max_vals \u001b[38;5;241m-\u001b[39m min_vals)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Save the normalized video\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[43msave_vid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_output_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_wm_normalized.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaving videos - took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimer\u001b[38;5;241m.\u001b[39mstop()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Augment video\u001b[39;00m\n",
      "File \u001b[0;32m~/09-videoseal/baselines/videoseal/utils/display.py:66\u001b[0m, in \u001b[0;36msave_vid\u001b[0;34m(vid, out_path, fps, crf)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Write the video file\u001b[39;00m\n\u001b[1;32m     65\u001b[0m options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcrf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_codec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibx264\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torchvision/io/video.py:133\u001b[0m, in \u001b[0;36mwrite_video\u001b[0;34m(filename, video_array, fps, video_codec, options, audio_array, audio_fps, audio_codec, audio_options)\u001b[0m\n\u001b[1;32m    131\u001b[0m     frame \u001b[38;5;241m=\u001b[39m av\u001b[38;5;241m.\u001b[39mVideoFrame\u001b[38;5;241m.\u001b[39mfrom_ndarray(img, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb24\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m     frame\u001b[38;5;241m.\u001b[39mpict_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNONE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m packet \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    134\u001b[0m         container\u001b[38;5;241m.\u001b[39mmux(packet)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Flush stream\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Directory containing videos\n",
    "video_dir = \"/checkpoint/pfz/projects/videoseal/assets/videos/metamoviegen_3s\"\n",
    "base_output_folder = \"outputs\"\n",
    "if not os.path.exists(base_output_folder):\n",
    "    os.makedirs(base_output_folder)\n",
    "\n",
    "# Example usage\n",
    "ckpts = {\n",
    "    # \"hidden\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.0_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=hidden/checkpoint.pth',\n",
    "    # \"unet\": '/private/home/hadyelsahar/work/code/videoseal/2024_logs/videoseal0.1/_lambda_d=0.5_lambda_i=0.5_optimizer=AdamW,lr=1e-4_videowam_step_size=4_video_start=500_embedder_model=unet_small2/checkpoint.pth',\n",
    "    # \"scaling_laws_smalldetector_tinyembedder\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1105-videoseal0.2-scalinglaws/_lambda_d=0.0_extractor_model=sam_small_embedder_model=0/checkpoint.pth\",\n",
    "    # \"scaling_laws_tinydetector_tinyembedder\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1105-videoseal0.2-scalinglaws/_lambda_d=0.0_extractor_model=sam_tiny_embedder_model=0/checkpoint.pth\",\n",
    "    # \"JND_fix_discloss\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1108-videoseal0.2-discloss-fix-removeunused-params/_attenuation=jnd_3_3_nbits=64_lambda_d=0.5_video_start=100/checkpoint.pth\",\n",
    "    # \"1111_discloss_sleepwake_highssim\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1109-videoseal0.2-discloss-fix-hing-sleepwake-4nodes/_scaling_w=0.1_lambda_i=0.25_disc_hinge_on_logits_fake=False_sleepwake=True_video_start=500/checkpoint.pth\"\n",
    "    # \"1111-finetuned\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-sleepwake-resume/_attenuation=jnd_1_1/checkpoint.pth\"\n",
    "    # \"1112-videoseal0.2\":\"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-archsearch-4nodes/_attenuation=None_nbits=64_finetune_detector_start=1000_embedder_model=unet_small2_quant/checkpoint.pth\",\n",
    "    # \"1118-yuv-400\":\"/checkpoint/pfz/2024_logs/1118_vseal_long_sab/_scheduler=0_optimizer=adopt,lr=1e-5/checkpoint400.pth\",\n",
    "    # \"1118-yuv-800\":\"/checkpoint/pfz/2024_logs/1118_vseal_long_sab/_scheduler=1_optimizer=AdamW,lr=1e-5/checkpoint.pth\",\n",
    "    # \"trustmark\": \"baseline/trustmark\",\n",
    "    # \"videoseal0.2b\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1111-videoseal0.2-archsearch-4nodes/_attenuation=None_nbits=64_finetune_detector_start=800_embedder_model=unet_small2_quant/checkpoint.pth\",\n",
    "    # \"videoseal0.2a\": \"/private/home/hadyelsahar/work/code/videoseal/2024_logs_large-exp/1109-videoseal0.2-discloss-fix-hing-sleepwake-4nodes/_scaling_w=0.5_lambda_i=0.5_disc_hinge_on_logits_fake=True_sleepwake=False_video_start=500/checkpoint.pth\",\n",
    "    # \"videoseal0.4\": \"/large_experiments/meres/hadyelsahar/2024_logs/1120-videoseal0.4/_scaling_w=0.5_sleepwake=False_videowam_step_size=4_extractor_model=sam_tiny/checkpoint.pth\",\n",
    "    \"wam\": \"baseline/wam\",\n",
    "}\n",
    "\n",
    "fps = 24 // 1\n",
    "# frames_per_clip = fps * 3  # 3s\n",
    "# frame_step = 1\n",
    "\n",
    "# a timer to measure the time\n",
    "timer = Timer()\n",
    "\n",
    "# Iterate over all checkpoints\n",
    "for model_name, ckpt in ckpts.items():\n",
    "    wam = setup_model_from_checkpoint(ckpt)\n",
    "    wam.eval()\n",
    "    wam.to(device)\n",
    "\n",
    "    # scaling_w = 0.3\n",
    "    # attenuation = JNDSimplified(in_channels=1, out_channels=3, blue=True)\n",
    "    # wam.attenuation = attenuation\n",
    "    # wam.blender.scaling_w = scaling_w\n",
    "\n",
    "    # scaling_w = 2.0\n",
    "    # attenuation = JNDSimplified(in_channels=1, out_channels=3, blue=True)\n",
    "    # wam.attenuation = attenuation\n",
    "    # wam.blender.scaling_w = scaling_w\n",
    "\n",
    "    wam.chunk_size = 64\n",
    "    wam.step_size = 1\n",
    "\n",
    "    # Iterate over all video files in the directory\n",
    "    video_files = [f for f in os.listdir(video_dir) if f.endswith(\".mp4\")][:1]\n",
    "\n",
    "    for video_file in tqdm(video_files, desc=f\"Processing Videos for {model_name}\"):\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        base_name = os.path.splitext(video_file)[0]\n",
    "\n",
    "        # Load video (assuming a function `load_video` exists)\n",
    "        timer.start()\n",
    "        vid, mask = VideoDataset.load_full_video_decord(video_path)\n",
    "        print(f\"loading video {video_path} - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Watermark embedding\n",
    "        timer.start()\n",
    "        # outputs = wam.embed_lowres_attenuation(vid, is_video=True)\n",
    "        outputs = wam.embed(vid, is_video=True)\n",
    "        print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # compute diff\n",
    "        imgs = vid  # b c h w\n",
    "        imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "        msgs = outputs[\"msgs\"]  # b k\n",
    "        diff = imgs_w - imgs\n",
    "\n",
    "        # save\n",
    "        timer.start()\n",
    "        save_vid(imgs, f\"{base_output_folder}/{model_name}_{base_name}_ori.mp4\", fps)\n",
    "        save_vid(imgs_w, f\"{base_output_folder}/{model_name}_{base_name}_wm.mp4\", fps)\n",
    "        save_vid(10*diff.abs(), f\"{base_output_folder}/{model_name}_{base_name}_diff.mp4\", fps)\n",
    "\n",
    "        # psnr\n",
    "        psnr_score = psnr(imgs, imgs_w, is_video=True).mean().item()\n",
    "        print(f\"PSNR: {psnr_score:.3f}\")\n",
    "\n",
    "        # Compute min and max values, reshape, and normalize\n",
    "        min_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).min(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        max_vals = diff.view(imgs.shape[0], imgs.shape[1], -1).max(dim=2, keepdim=True)[0].view(imgs.shape[0], imgs.shape[1], 1, 1)\n",
    "        normalized_images = (diff - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "        # Save the normalized video\n",
    "        save_vid(normalized_images, f\"{base_output_folder}/{model_name}_{base_name}_wm_normalized.mp4\", fps)\n",
    "        print(f\"saving videos - took {timer.stop():.2f}s\")\n",
    "\n",
    "        # Augment video\n",
    "        print(f\"compressing and detecting watermarks\")\n",
    "        # for crf in [-1, 23, 40, 60]:\n",
    "        #     if crf == -1:\n",
    "        #         imgs_aug = imgs_w\n",
    "        #     else:\n",
    "        #         imgs_aug, _ = H264()(imgs_w, crf=crf)\n",
    "        for ii in range(1):\n",
    "            imgs_aug, _ = H264()(imgs_w, crf=40)\n",
    "            imgs_aug, _ = Crop()(imgs_aug, size=0.75)\n",
    "\n",
    "            save_vid(imgs_aug, f\"{base_output_folder}/{model_name}_{base_name}_wm_crop_08_h264_40.mp4\", fps)\n",
    "            # detect\n",
    "            timer.start()\n",
    "            # outputs = wam.detect(imgs_aug, is_video=True)\n",
    "            # preds = outputs[\"preds\"]\n",
    "            # bit_preds = preds[:, 1:]  # b k ...\n",
    "            # bit_accuracy_ = bit_accuracy(\n",
    "            #     bit_preds,\n",
    "            #     msgs\n",
    "            # ).nanmean().item()\n",
    "            bit_preds = wam.detect_and_aggregate(imgs_aug)\n",
    "            bit_accuracy_ = bit_accuracy(\n",
    "                bit_preds,\n",
    "                msgs[:1]\n",
    "            ).nanmean().item()\n",
    "            pvalue_ = pvalue(\n",
    "                bit_preds,\n",
    "                msgs[:1]\n",
    "            ).nanmean().item()\n",
    "            capacity_ = capacity(\n",
    "                bit_preds,\n",
    "                msgs[:1]\n",
    "            ).nanmean().item()\n",
    "            # print(f\"CRF={crf} - Bit Accuracy: {bit_accuracy_:.3f} - P-Value: {pvalue_:0.2e} - Capacity: {capacity_:.3f} - took {timer.stop():.2f}s\")\n",
    "            print(f\"H264, Crop - Bit Accuracy: {bit_accuracy_:.3f} - P-Value: {pvalue_:0.2e} - Capacity: {capacity_:.3f} - took {timer.stop():.2f}s\")\n",
    "\n",
    "        del vid, outputs, imgs, imgs_w, diff, min_vals, max_vals, normalized_images\n",
    "\n",
    "    # Free model from GPU\n",
    "    del wam\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /large_experiments/meres/hadyelsahar/2024_logs/1120-videoseal0.4/_scaling_w=0.5_sleepwake=False_videowam_step_size=4_extractor_model=sam_tiny/checkpoint.pth with message: <All keys matched successfully>\n",
      "CRF=60 - Bit Accuracy: 1.000 - P-Value: 5.42e-20 - Capacity: 64.000 - took 0.82s\n"
     ]
    }
   ],
   "source": [
    "wam = setup_model_from_checkpoint(ckpt)\n",
    "wam.eval()\n",
    "wam.to(device)\n",
    "\n",
    "video_path = \"/private/home/pfz/09-videoseal/baselines/outputs/videoseal0.4_01_wm_crop_08_h264_40.mp4\"\n",
    "vid, mask = VideoDataset.load_full_video_decord(video_path)\n",
    "\n",
    "timer.start()\n",
    "bit_preds = wam.detect_and_aggregate(imgs_aug)\n",
    "bit_accuracy_ = bit_accuracy(\n",
    "    bit_preds,\n",
    "    msgs[:1]\n",
    ").nanmean().item()\n",
    "pvalue_ = pvalue(\n",
    "    bit_preds,\n",
    "    msgs[:1]\n",
    ").nanmean().item()\n",
    "capacity_ = capacity(\n",
    "    bit_preds,\n",
    "    msgs[:1]\n",
    ").nanmean().item()\n",
    "print(f\"CRF={crf} - Bit Accuracy: {bit_accuracy_:.3f} - P-Value: {pvalue_:0.2e} - Capacity: {capacity_:.3f} - took {timer.stop():.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1,  ..., 0, 1, 1],\n",
       "        [1, 0, 1,  ..., 0, 1, 1],\n",
       "        [1, 0, 1,  ..., 0, 1, 1],\n",
       "        ...,\n",
       "        [1, 0, 1,  ..., 0, 1, 1],\n",
       "        [1, 0, 1,  ..., 0, 1, 1],\n",
       "        [1, 0, 1,  ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False,  True,  True, False,  True,  True, False, False,  True,\n",
       "         False,  True, False,  True,  True, False,  True, False,  True,  True,\n",
       "         False, False,  True, False, False,  True, False,  True,  True,  True,\n",
       "         False,  True, False, False,  True, False, False,  True, False,  True,\n",
       "         False,  True,  True, False, False, False,  True, False,  True,  True,\n",
       "         False, False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "         False, False,  True,  True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bit_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
