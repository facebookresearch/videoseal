{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "FN = \"/private/home/soucek/videoseal/1122_vseal_04_rgb_96bits_total_gnorm=1.0_sleepwake=False_scheduler=1_optimizer=AdamW,lr=1e-5_extractor_model=sam_small.epoch700.pth\"\n",
    "\n",
    "missing_keys=['embedder.unet.inc.double_conv.0.conv.weight', 'embedder.unet.inc.double_conv.3.conv.weight', 'embedder.unet.inc.res_conv.conv.weight', 'embedder.unet.inc.res_conv.conv.bias', 'embedder.unet.downs.0.conv.double_conv.0.conv.weight', 'embedder.unet.downs.0.conv.double_conv.3.conv.weight', 'embedder.unet.downs.0.conv.res_conv.conv.weight', 'embedder.unet.downs.0.conv.res_conv.conv.bias', 'embedder.unet.downs.1.conv.double_conv.0.conv.weight', 'embedder.unet.downs.1.conv.double_conv.3.conv.weight', 'embedder.unet.downs.1.conv.res_conv.conv.weight', 'embedder.unet.downs.1.conv.res_conv.conv.bias', 'embedder.unet.downs.2.conv.double_conv.0.conv.weight', 'embedder.unet.downs.2.conv.double_conv.3.conv.weight', 'embedder.unet.downs.2.conv.res_conv.conv.weight', 'embedder.unet.downs.2.conv.res_conv.conv.bias', 'embedder.unet.bottleneck.model.0.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.0.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.0.res_conv.conv.weight', 'embedder.unet.bottleneck.model.0.res_conv.conv.bias', 'embedder.unet.bottleneck.model.1.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.1.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.1.res_conv.conv.weight', 'embedder.unet.bottleneck.model.1.res_conv.conv.bias', 'embedder.unet.bottleneck.model.2.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.2.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.2.res_conv.conv.weight', 'embedder.unet.bottleneck.model.2.res_conv.conv.bias', 'embedder.unet.bottleneck.model.3.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.3.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.3.res_conv.conv.weight', 'embedder.unet.bottleneck.model.3.res_conv.conv.bias', 'embedder.unet.bottleneck.model.4.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.4.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.4.res_conv.conv.weight', 'embedder.unet.bottleneck.model.4.res_conv.conv.bias', 'embedder.unet.bottleneck.model.5.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.5.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.5.res_conv.conv.weight', 'embedder.unet.bottleneck.model.5.res_conv.conv.bias', 'embedder.unet.bottleneck.model.6.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.6.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.6.res_conv.conv.weight', 'embedder.unet.bottleneck.model.6.res_conv.conv.bias', 'embedder.unet.bottleneck.model.7.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.7.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.7.res_conv.conv.weight', 'embedder.unet.bottleneck.model.7.res_conv.conv.bias', 'embedder.unet.ups.0.conv.double_conv.0.conv.weight', 'embedder.unet.ups.0.conv.double_conv.3.conv.weight', 'embedder.unet.ups.0.conv.res_conv.conv.weight', 'embedder.unet.ups.0.conv.res_conv.conv.bias', 'embedder.unet.ups.1.conv.double_conv.0.conv.weight', 'embedder.unet.ups.1.conv.double_conv.3.conv.weight', 'embedder.unet.ups.1.conv.res_conv.conv.weight', 'embedder.unet.ups.1.conv.res_conv.conv.bias', 'embedder.unet.ups.2.conv.double_conv.0.conv.weight', 'embedder.unet.ups.2.conv.double_conv.3.conv.weight', 'embedder.unet.ups.2.conv.res_conv.conv.weight', 'embedder.unet.ups.2.conv.res_conv.conv.bias']\n",
    "unexpected_keys=['embedder.unet.inc.double_conv.0.weight', 'embedder.unet.inc.double_conv.3.weight', 'embedder.unet.inc.res_conv.weight', 'embedder.unet.inc.res_conv.bias', 'embedder.unet.downs.0.conv.double_conv.0.weight', 'embedder.unet.downs.0.conv.double_conv.3.weight', 'embedder.unet.downs.0.conv.res_conv.weight', 'embedder.unet.downs.0.conv.res_conv.bias', 'embedder.unet.downs.1.conv.double_conv.0.weight', 'embedder.unet.downs.1.conv.double_conv.3.weight', 'embedder.unet.downs.1.conv.res_conv.weight', 'embedder.unet.downs.1.conv.res_conv.bias', 'embedder.unet.downs.2.conv.double_conv.0.weight', 'embedder.unet.downs.2.conv.double_conv.3.weight', 'embedder.unet.downs.2.conv.res_conv.weight', 'embedder.unet.downs.2.conv.res_conv.bias', 'embedder.unet.bottleneck.model.0.double_conv.0.weight', 'embedder.unet.bottleneck.model.0.double_conv.3.weight', 'embedder.unet.bottleneck.model.0.res_conv.weight', 'embedder.unet.bottleneck.model.0.res_conv.bias', 'embedder.unet.bottleneck.model.1.double_conv.0.weight', 'embedder.unet.bottleneck.model.1.double_conv.3.weight', 'embedder.unet.bottleneck.model.1.res_conv.weight', 'embedder.unet.bottleneck.model.1.res_conv.bias', 'embedder.unet.bottleneck.model.2.double_conv.0.weight', 'embedder.unet.bottleneck.model.2.double_conv.3.weight', 'embedder.unet.bottleneck.model.2.res_conv.weight', 'embedder.unet.bottleneck.model.2.res_conv.bias', 'embedder.unet.bottleneck.model.3.double_conv.0.weight', 'embedder.unet.bottleneck.model.3.double_conv.3.weight', 'embedder.unet.bottleneck.model.3.res_conv.weight', 'embedder.unet.bottleneck.model.3.res_conv.bias', 'embedder.unet.bottleneck.model.4.double_conv.0.weight', 'embedder.unet.bottleneck.model.4.double_conv.3.weight', 'embedder.unet.bottleneck.model.4.res_conv.weight', 'embedder.unet.bottleneck.model.4.res_conv.bias', 'embedder.unet.bottleneck.model.5.double_conv.0.weight', 'embedder.unet.bottleneck.model.5.double_conv.3.weight', 'embedder.unet.bottleneck.model.5.res_conv.weight', 'embedder.unet.bottleneck.model.5.res_conv.bias', 'embedder.unet.bottleneck.model.6.double_conv.0.weight', 'embedder.unet.bottleneck.model.6.double_conv.3.weight', 'embedder.unet.bottleneck.model.6.res_conv.weight', 'embedder.unet.bottleneck.model.6.res_conv.bias', 'embedder.unet.bottleneck.model.7.double_conv.0.weight', 'embedder.unet.bottleneck.model.7.double_conv.3.weight', 'embedder.unet.bottleneck.model.7.res_conv.weight', 'embedder.unet.bottleneck.model.7.res_conv.bias', 'embedder.unet.ups.0.conv.double_conv.0.weight', 'embedder.unet.ups.0.conv.double_conv.3.weight', 'embedder.unet.ups.0.conv.res_conv.weight', 'embedder.unet.ups.0.conv.res_conv.bias', 'embedder.unet.ups.1.conv.double_conv.0.weight', 'embedder.unet.ups.1.conv.double_conv.3.weight', 'embedder.unet.ups.1.conv.res_conv.weight', 'embedder.unet.ups.1.conv.res_conv.bias', 'embedder.unet.ups.2.conv.double_conv.0.weight', 'embedder.unet.ups.2.conv.double_conv.3.weight', 'embedder.unet.ups.2.conv.res_conv.weight', 'embedder.unet.ups.2.conv.res_conv.bias']\n",
    "\n",
    "checkpoint = torch.load(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in missing_keys:\n",
    "    k2 = k.replace(\".conv.weight\", \".weight\").replace(\".conv.bias\", \".bias\")\n",
    "    assert k2 in unexpected_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = checkpoint[\"model\"]\n",
    "for k in missing_keys:\n",
    "    k2 = k.replace(\".conv.weight\", \".weight\").replace(\".conv.bias\", \".bias\")\n",
    "    if \".bias\" in k:\n",
    "        m[k] = m[k2]\n",
    "        del m[k2]\n",
    "    else:\n",
    "        s = list(m[k2].shape)\n",
    "        assert len(s) == 4\n",
    "        if s[2:] == [1,1]:\n",
    "            m[k] = m[k2].unsqueeze(2)\n",
    "            del m[k2]\n",
    "            continue\n",
    "        assert s[2:] == [3,3]\n",
    "\n",
    "        nw = m[k2].unsqueeze(2)\n",
    "        nw = torch.cat([torch.zeros_like(nw), nw, torch.zeros_like(nw)], 2)\n",
    "\n",
    "        m[k] = nw\n",
    "        del m[k2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, FN.replace(\".pth\", \".conv3d_converted.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv2p1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "FN = \"/private/home/soucek/videoseal/1122_vseal_04_rgb_96bits_total_gnorm=1.0_sleepwake=False_scheduler=1_optimizer=AdamW,lr=1e-5_extractor_model=sam_small.epoch700.pth\"\n",
    "checkpoint = torch.load(FN)\n",
    "\n",
    "missing_keys=['embedder.unet.inc.double_conv.0.conv.weight', 'embedder.unet.inc.double_conv.0.temp_conv.weight', 'embedder.unet.inc.double_conv.3.conv.weight', 'embedder.unet.inc.double_conv.3.temp_conv.weight', 'embedder.unet.inc.res_conv.conv.weight', 'embedder.unet.inc.res_conv.conv.bias', 'embedder.unet.downs.0.conv.double_conv.0.conv.weight', 'embedder.unet.downs.0.conv.double_conv.0.temp_conv.weight', 'embedder.unet.downs.0.conv.double_conv.3.conv.weight', 'embedder.unet.downs.0.conv.double_conv.3.temp_conv.weight', 'embedder.unet.downs.0.conv.res_conv.conv.weight', 'embedder.unet.downs.0.conv.res_conv.conv.bias', 'embedder.unet.downs.1.conv.double_conv.0.conv.weight', 'embedder.unet.downs.1.conv.double_conv.0.temp_conv.weight', 'embedder.unet.downs.1.conv.double_conv.3.conv.weight', 'embedder.unet.downs.1.conv.double_conv.3.temp_conv.weight', 'embedder.unet.downs.1.conv.res_conv.conv.weight', 'embedder.unet.downs.1.conv.res_conv.conv.bias', 'embedder.unet.downs.2.conv.double_conv.0.conv.weight', 'embedder.unet.downs.2.conv.double_conv.0.temp_conv.weight', 'embedder.unet.downs.2.conv.double_conv.3.conv.weight', 'embedder.unet.downs.2.conv.double_conv.3.temp_conv.weight', 'embedder.unet.downs.2.conv.res_conv.conv.weight', 'embedder.unet.downs.2.conv.res_conv.conv.bias', 'embedder.unet.bottleneck.model.0.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.0.double_conv.0.temp_conv.weight', 'embedder.unet.bottleneck.model.0.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.0.double_conv.3.temp_conv.weight', 'embedder.unet.bottleneck.model.0.res_conv.conv.weight', 'embedder.unet.bottleneck.model.0.res_conv.conv.bias', 'embedder.unet.bottleneck.model.1.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.1.double_conv.0.temp_conv.weight', 'embedder.unet.bottleneck.model.1.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.1.double_conv.3.temp_conv.weight', 'embedder.unet.bottleneck.model.1.res_conv.conv.weight', 'embedder.unet.bottleneck.model.1.res_conv.conv.bias', 'embedder.unet.bottleneck.model.2.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.2.double_conv.0.temp_conv.weight', 'embedder.unet.bottleneck.model.2.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.2.double_conv.3.temp_conv.weight', 'embedder.unet.bottleneck.model.2.res_conv.conv.weight', 'embedder.unet.bottleneck.model.2.res_conv.conv.bias', 'embedder.unet.bottleneck.model.3.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.3.double_conv.0.temp_conv.weight', 'embedder.unet.bottleneck.model.3.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.3.double_conv.3.temp_conv.weight', 'embedder.unet.bottleneck.model.3.res_conv.conv.weight', 'embedder.unet.bottleneck.model.3.res_conv.conv.bias', 'embedder.unet.bottleneck.model.4.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.4.double_conv.0.temp_conv.weight', 'embedder.unet.bottleneck.model.4.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.4.double_conv.3.temp_conv.weight', 'embedder.unet.bottleneck.model.4.res_conv.conv.weight', 'embedder.unet.bottleneck.model.4.res_conv.conv.bias', 'embedder.unet.bottleneck.model.5.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.5.double_conv.0.temp_conv.weight', 'embedder.unet.bottleneck.model.5.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.5.double_conv.3.temp_conv.weight', 'embedder.unet.bottleneck.model.5.res_conv.conv.weight', 'embedder.unet.bottleneck.model.5.res_conv.conv.bias', 'embedder.unet.bottleneck.model.6.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.6.double_conv.0.temp_conv.weight', 'embedder.unet.bottleneck.model.6.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.6.double_conv.3.temp_conv.weight', 'embedder.unet.bottleneck.model.6.res_conv.conv.weight', 'embedder.unet.bottleneck.model.6.res_conv.conv.bias', 'embedder.unet.bottleneck.model.7.double_conv.0.conv.weight', 'embedder.unet.bottleneck.model.7.double_conv.0.temp_conv.weight', 'embedder.unet.bottleneck.model.7.double_conv.3.conv.weight', 'embedder.unet.bottleneck.model.7.double_conv.3.temp_conv.weight', 'embedder.unet.bottleneck.model.7.res_conv.conv.weight', 'embedder.unet.bottleneck.model.7.res_conv.conv.bias', 'embedder.unet.ups.0.conv.double_conv.0.conv.weight', 'embedder.unet.ups.0.conv.double_conv.0.temp_conv.weight', 'embedder.unet.ups.0.conv.double_conv.3.conv.weight', 'embedder.unet.ups.0.conv.double_conv.3.temp_conv.weight', 'embedder.unet.ups.0.conv.res_conv.conv.weight', 'embedder.unet.ups.0.conv.res_conv.conv.bias', 'embedder.unet.ups.1.conv.double_conv.0.conv.weight', 'embedder.unet.ups.1.conv.double_conv.0.temp_conv.weight', 'embedder.unet.ups.1.conv.double_conv.3.conv.weight', 'embedder.unet.ups.1.conv.double_conv.3.temp_conv.weight', 'embedder.unet.ups.1.conv.res_conv.conv.weight', 'embedder.unet.ups.1.conv.res_conv.conv.bias', 'embedder.unet.ups.2.conv.double_conv.0.conv.weight', 'embedder.unet.ups.2.conv.double_conv.0.temp_conv.weight', 'embedder.unet.ups.2.conv.double_conv.3.conv.weight', 'embedder.unet.ups.2.conv.double_conv.3.temp_conv.weight', 'embedder.unet.ups.2.conv.res_conv.conv.weight', 'embedder.unet.ups.2.conv.res_conv.conv.bias']\n",
    "unexpected_keys=['embedder.unet.inc.double_conv.0.weight', 'embedder.unet.inc.double_conv.3.weight', 'embedder.unet.inc.res_conv.weight', 'embedder.unet.inc.res_conv.bias', 'embedder.unet.downs.0.conv.double_conv.0.weight', 'embedder.unet.downs.0.conv.double_conv.3.weight', 'embedder.unet.downs.0.conv.res_conv.weight', 'embedder.unet.downs.0.conv.res_conv.bias', 'embedder.unet.downs.1.conv.double_conv.0.weight', 'embedder.unet.downs.1.conv.double_conv.3.weight', 'embedder.unet.downs.1.conv.res_conv.weight', 'embedder.unet.downs.1.conv.res_conv.bias', 'embedder.unet.downs.2.conv.double_conv.0.weight', 'embedder.unet.downs.2.conv.double_conv.3.weight', 'embedder.unet.downs.2.conv.res_conv.weight', 'embedder.unet.downs.2.conv.res_conv.bias', 'embedder.unet.bottleneck.model.0.double_conv.0.weight', 'embedder.unet.bottleneck.model.0.double_conv.3.weight', 'embedder.unet.bottleneck.model.0.res_conv.weight', 'embedder.unet.bottleneck.model.0.res_conv.bias', 'embedder.unet.bottleneck.model.1.double_conv.0.weight', 'embedder.unet.bottleneck.model.1.double_conv.3.weight', 'embedder.unet.bottleneck.model.1.res_conv.weight', 'embedder.unet.bottleneck.model.1.res_conv.bias', 'embedder.unet.bottleneck.model.2.double_conv.0.weight', 'embedder.unet.bottleneck.model.2.double_conv.3.weight', 'embedder.unet.bottleneck.model.2.res_conv.weight', 'embedder.unet.bottleneck.model.2.res_conv.bias', 'embedder.unet.bottleneck.model.3.double_conv.0.weight', 'embedder.unet.bottleneck.model.3.double_conv.3.weight', 'embedder.unet.bottleneck.model.3.res_conv.weight', 'embedder.unet.bottleneck.model.3.res_conv.bias', 'embedder.unet.bottleneck.model.4.double_conv.0.weight', 'embedder.unet.bottleneck.model.4.double_conv.3.weight', 'embedder.unet.bottleneck.model.4.res_conv.weight', 'embedder.unet.bottleneck.model.4.res_conv.bias', 'embedder.unet.bottleneck.model.5.double_conv.0.weight', 'embedder.unet.bottleneck.model.5.double_conv.3.weight', 'embedder.unet.bottleneck.model.5.res_conv.weight', 'embedder.unet.bottleneck.model.5.res_conv.bias', 'embedder.unet.bottleneck.model.6.double_conv.0.weight', 'embedder.unet.bottleneck.model.6.double_conv.3.weight', 'embedder.unet.bottleneck.model.6.res_conv.weight', 'embedder.unet.bottleneck.model.6.res_conv.bias', 'embedder.unet.bottleneck.model.7.double_conv.0.weight', 'embedder.unet.bottleneck.model.7.double_conv.3.weight', 'embedder.unet.bottleneck.model.7.res_conv.weight', 'embedder.unet.bottleneck.model.7.res_conv.bias', 'embedder.unet.ups.0.conv.double_conv.0.weight', 'embedder.unet.ups.0.conv.double_conv.3.weight', 'embedder.unet.ups.0.conv.res_conv.weight', 'embedder.unet.ups.0.conv.res_conv.bias', 'embedder.unet.ups.1.conv.double_conv.0.weight', 'embedder.unet.ups.1.conv.double_conv.3.weight', 'embedder.unet.ups.1.conv.res_conv.weight', 'embedder.unet.ups.1.conv.res_conv.bias', 'embedder.unet.ups.2.conv.double_conv.0.weight', 'embedder.unet.ups.2.conv.double_conv.3.weight', 'embedder.unet.ups.2.conv.res_conv.weight', 'embedder.unet.ups.2.conv.res_conv.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in missing_keys:\n",
    "    k2 = k.replace(\".conv.weight\", \".weight\").replace(\".conv.bias\", \".bias\")\n",
    "    if \".temp_conv.\" in k:\n",
    "        assert k.replace(\".temp_conv.\", \".conv.\") in missing_keys\n",
    "        continue\n",
    "    assert k2 in unexpected_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = checkpoint[\"model\"]\n",
    "for k in missing_keys:\n",
    "    if \".temp_conv.\" in k:\n",
    "        t = m[k.replace(\".temp_conv.\", \".conv.\")]\n",
    "        out_ch, _, ks, ks2 = t.shape\n",
    "        assert ks == ks2\n",
    "        nw = torch.cat([\n",
    "            torch.zeros((out_ch, out_ch, ks // 2, 1, 1), dtype=t.dtype, device=t.device),\n",
    "            torch.eye(out_ch, dtype=t.dtype, device=t.device).view(out_ch, out_ch, 1, 1, 1),\n",
    "            torch.zeros((out_ch, out_ch, ks // 2, 1, 1), dtype=t.dtype, device=t.device)\n",
    "        ], 2)\n",
    "        m[k] = nw\n",
    "    else:\n",
    "        k2 = k.replace(\".conv.weight\", \".weight\").replace(\".conv.bias\", \".bias\")\n",
    "        m[k] = m[k2]\n",
    "        del m[k2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in missing_keys:\n",
    "    assert k in m\n",
    "for k in unexpected_keys:\n",
    "    assert k not in m\n",
    "\n",
    "torch.save(checkpoint, FN.replace(\".pth\", \".conv2p1d_converted.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from videoseal.modules.vit import ImageEncoderViT\n",
    "FN = \"/private/home/soucek/videoseal/1122_vseal_04_rgb_96bits_total_gnorm=1.0_sleepwake=False_scheduler=1_optimizer=AdamW,lr=1e-5_extractor_model=sam_small.epoch700.conv3d_converted.pth\"\n",
    "\n",
    "checkpoint = torch.load(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_vanilla = ImageEncoderViT(\n",
    "    img_size=256,\n",
    "    embed_dim=384,\n",
    "    out_chans=384,\n",
    "    depth=12,\n",
    "    num_heads=6,\n",
    "    patch_size=16,\n",
    "    global_attn_indexes=[2, 5, 8, 11],\n",
    "    window_size=8,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    use_rel_pos=True,\n",
    ")\n",
    "\n",
    "extractor_temporal = ImageEncoderViT(\n",
    "    img_size=256,\n",
    "    embed_dim=384,\n",
    "    out_chans=384,\n",
    "    depth=12,\n",
    "    num_heads=6,\n",
    "    patch_size=16,\n",
    "    global_attn_indexes=[2, 5, 8, 11],\n",
    "    window_size=8,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    use_rel_pos=True,\n",
    "    additional_temporal_attention=True,\n",
    "    max_temporal_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vanilla = {k: v.shape for k, v in extractor_vanilla.named_parameters()}\n",
    "vars_temporal = {k: v.shape for k, v in extractor_temporal.named_parameters()}\n",
    "\n",
    "vars_checkpoint = [k[len(\"detector.image_encoder.\"):] for k in checkpoint[\"model\"].keys() if k.startswith(\"detector.image_encoder\")]\n",
    "new_vars = [k for k in vars_temporal if k not in vars_checkpoint]\n",
    "\n",
    "for k in vars_checkpoint:\n",
    "    assert k in vars_vanilla\n",
    "for k in vars_vanilla:\n",
    "    assert k in vars_checkpoint\n",
    "    assert k in vars_temporal\n",
    "\n",
    "for k in new_vars:\n",
    "    if k.startswith(\"temp_blocks.0\"):\n",
    "        print(k)\n",
    "    if k.startswith(\"temp_blocks.\"):\n",
    "        continue\n",
    "    print(k)\n",
    "\n",
    "for b in extractor_temporal.temp_blocks:\n",
    "    b.mlp.lin2.bias.data.fill_(0.)\n",
    "    b.mlp.lin2.weight.data.fill_(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = checkpoint[\"model\"]\n",
    "sd = extractor_temporal.state_dict()\n",
    "\n",
    "for v in new_vars:\n",
    "    print(f\"detector.image_encoder.{v:33}...\", (sd[v] == 0).all().item(), sd[v].shape)\n",
    "    m[f\"detector.image_encoder.{v}\"] = sd[v]\n",
    "\n",
    "torch.save(checkpoint, FN.replace(\".pth\", \".temp_extr.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
