{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/09-videoseal/videoseal-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# run in the root of the repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/private/home/pfz/miniconda3/envs/img/lib/python3.12/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "from videoseal.utils.display import save_img\n",
    "from videoseal.utils import Timer\n",
    "from videoseal.evals.full import setup_model_from_checkpoint\n",
    "from videoseal.evals.metrics import bit_accuracy, psnr, ssim\n",
    "from videoseal.augmentation import Identity, JPEG\n",
    "from videoseal.modules.jnd import JND, VarianceBasedJND\n",
    "\n",
    "import os\n",
    "import omegaconf\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "\n",
    "device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /checkpoint/pfz/2025_logs/0306_vseal_ydisc_release_bis/_nbits=256/checkpoint600.pth with message: <All keys matched successfully>\n",
      "{'file': '/private/home/pfz/_images/tahiti.png', 'bit_accuracy': 1.0, 'psnr': 47.33894729614258, 'ssim': 0.9984757304191589, 'bit_accuracy_qf80': 0.99609375, 'bit_accuracy_qf40': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Directory containing videos\n",
    "num_imgs = 10\n",
    "assets_dir = \"assets/imgs\"\n",
    "base_output_dir = \"outputs\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "wam = setup_model_from_checkpoint(\"/checkpoint/pfz/2025_logs/0306_vseal_ydisc_release_bis/_nbits=256/checkpoint600.pth\")\n",
    "wam.blender.scaling_w = 0.2\n",
    "wam.eval()\n",
    "wam.to(device)\n",
    "    \n",
    "# wam.compile()\n",
    "\n",
    "# Iterate over all video files in the directory\n",
    "file = \"/private/home/pfz/_images/tahiti.png\"\n",
    "imgs = Image.open(file, \"r\").convert(\"RGB\")  # keep only rgb channels\n",
    "imgs = to_tensor(imgs).unsqueeze(0).float()\n",
    "\n",
    "# Watermark em\n",
    "outputs = wam.embed(imgs, is_video=False, lowres_attenuation=True)\n",
    "torch.cuda.synchronize()\n",
    "# print(f\"embedding watermark  - took {timer.stop():.2f}s\")\n",
    "\n",
    "# compute diff\n",
    "imgs_w = outputs[\"imgs_w\"]  # b c h w\n",
    "msgs = outputs[\"msgs\"]  # b k\n",
    "diff = imgs_w - imgs\n",
    "\n",
    "# save\n",
    "imgs_aug = imgs_w\n",
    "outputs = wam.detect(imgs_aug, is_video=False)\n",
    "metrics = {\n",
    "    \"file\": file,\n",
    "    \"bit_accuracy\": bit_accuracy(\n",
    "        outputs[\"preds\"][:, 1:],\n",
    "        msgs\n",
    "    ).nanmean().item(),\n",
    "    \"psnr\": psnr(imgs_w, imgs).item(),\n",
    "    \"ssim\": ssim(imgs_w, imgs).item()\n",
    "}\n",
    "\n",
    "# Augment video\n",
    "# print(f\"compressing and detecting watermarks\")\n",
    "for qf in [80, 40]:\n",
    "    imgs_aug, _ = JPEG()(imgs_w, None,qf)\n",
    "\n",
    "    outputs = wam.detect(imgs_aug, is_video=True)\n",
    "    preds = outputs[\"preds\"]\n",
    "    # print(preds)\n",
    "    bit_preds = preds[:, 1:]  # b k ...\n",
    "    bit_accuracy_ = bit_accuracy(\n",
    "        bit_preds,\n",
    "        msgs\n",
    "    ).nanmean().item()\n",
    "    \n",
    "    metrics[f\"bit_accuracy_qf{qf}\"] = bit_accuracy_\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create torchscript for wam.embedder\n",
    "\n",
    "class EmbedderWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        return self.model.embed(imgs, is_video=False, lowres_attenuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedNodeError",
     "evalue": "function definitions aren't supported:\n  File \"/private/home/pfz/09-videoseal/videoseal-dev/videoseal/modules/unet.py\", line 206\n    \n        # Upward path\n        def concat_skip_connect(x): return torch.cat(\n        ~~~ <--- HERE\n            (x, hiddens.pop() * self.connect_scale), dim=1)\n        for ublock in self.ups:\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedNodeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m embedder \u001b[38;5;241m=\u001b[39m EmbedderWrapper(wam)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# save\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39msave(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscript\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedder\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/embedder.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_script.py:1432\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m _TOPLEVEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_script_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_frames_up\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_frames_up\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_rcb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_rcb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1440\u001b[0m     _TOPLEVEL \u001b[38;5;241m=\u001b[39m prev\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_script.py:1146\u001b[0m, in \u001b[0;36m_script_impl\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m   1145\u001b[0m     obj \u001b[38;5;241m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_script_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_methods_to_compile\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1150\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m__prepare_scriptable__() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__prepare_scriptable__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obj  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:559\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    558\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:632\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    629\u001b[0m     script_module\u001b[38;5;241m.\u001b[39m_concrete_type \u001b[38;5;241m=\u001b[39m concrete_type\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m script_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursiveScriptModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpp_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_script.py:649\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    648\u001b[0m script_module \u001b[38;5;241m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 649\u001b[0m \u001b[43minit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m RecursiveScriptModule\u001b[38;5;241m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:608\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    605\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m orig_value\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43morig_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_concrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m cpp_module\u001b[38;5;241m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    613\u001b[0m script_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m scripted\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:632\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    629\u001b[0m     script_module\u001b[38;5;241m.\u001b[39m_concrete_type \u001b[38;5;241m=\u001b[39m concrete_type\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m script_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursiveScriptModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpp_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_script.py:649\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    648\u001b[0m script_module \u001b[38;5;241m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 649\u001b[0m \u001b[43minit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m RecursiveScriptModule\u001b[38;5;241m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:608\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    605\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m orig_value\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43morig_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_concrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m cpp_module\u001b[38;5;241m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    613\u001b[0m script_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m scripted\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:632\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    629\u001b[0m     script_module\u001b[38;5;241m.\u001b[39m_concrete_type \u001b[38;5;241m=\u001b[39m concrete_type\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m script_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursiveScriptModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpp_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_script.py:649\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    648\u001b[0m script_module \u001b[38;5;241m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 649\u001b[0m \u001b[43minit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m RecursiveScriptModule\u001b[38;5;241m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:608\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    605\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m orig_value\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43morig_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_concrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m cpp_module\u001b[38;5;241m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    613\u001b[0m script_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m scripted\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:572\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03mConvert an nn.Module to a RecursiveScriptModule.\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    stubs_fn:  Lambda that takes an nn.Module and generates a list of ScriptMethodStubs to compile.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m cpp_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_create_module_with_type(concrete_type\u001b[38;5;241m.\u001b[39mjit_type)\n\u001b[0;32m--> 572\u001b[0m method_stubs \u001b[38;5;241m=\u001b[39m \u001b[43mstubs_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m property_stubs \u001b[38;5;241m=\u001b[39m get_property_stubs(nn_module)\n\u001b[1;32m    574\u001b[0m hook_stubs, pre_hook_stubs \u001b[38;5;241m=\u001b[39m get_hook_stubs(nn_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:895\u001b[0m, in \u001b[0;36minfer_methods_to_compile\u001b[0;34m(nn_module)\u001b[0m\n\u001b[1;32m    893\u001b[0m stubs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m uniqued_methods:\n\u001b[0;32m--> 895\u001b[0m     stubs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmake_stub_from_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m overload_stubs \u001b[38;5;241m+\u001b[39m stubs\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:88\u001b[0m, in \u001b[0;36mmake_stub_from_method\u001b[0;34m(nn_module, method_name)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Make sure the name present in the resulting AST will match the name\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# requested here. The only time they don't match is if you do something\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# like:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# In this case, the actual function object will have the name `_forward`,\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# even though we requested a stub for `forward`.\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_stub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/_recursive.py:72\u001b[0m, in \u001b[0;36mmake_stub\u001b[0;34m(func, name)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_stub\u001b[39m(func, name):\n\u001b[1;32m     71\u001b[0m     rcb \u001b[38;5;241m=\u001b[39m _jit_internal\u001b[38;5;241m.\u001b[39mcreateResolutionCallbackFromClosure(func)\n\u001b[0;32m---> 72\u001b[0m     ast \u001b[38;5;241m=\u001b[39m \u001b[43mget_jit_def\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRecursiveScriptModule\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ScriptMethodStub(rcb, ast, func)\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/frontend.py:373\u001b[0m, in \u001b[0;36mget_jit_def\u001b[0;34m(fn, def_name, self_name, is_classmethod)\u001b[0m\n\u001b[1;32m    370\u001b[0m     qualname \u001b[38;5;241m=\u001b[39m get_qualified_name(fn)\n\u001b[1;32m    371\u001b[0m     pdt_arg_types \u001b[38;5;241m=\u001b[39m type_trace_db\u001b[38;5;241m.\u001b[39mget_args_types(qualname)\n\u001b[0;32m--> 373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparsed_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_line\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdef_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mself_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpdt_arg_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdt_arg_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/frontend.py:434\u001b[0m, in \u001b[0;36mbuild_def\u001b[0;34m(ctx, py_def, type_line, def_name, self_name, pdt_arg_types)\u001b[0m\n\u001b[1;32m    431\u001b[0m     type_comment_decl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mparse_type_comment(type_line)\n\u001b[1;32m    432\u001b[0m     decl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mmerge_type_from_type_comment(decl, type_comment_decl, is_method)\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Def(Ident(r, def_name), decl, \u001b[43mbuild_stmts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/frontend.py:196\u001b[0m, in \u001b[0;36mbuild_stmts\u001b[0;34m(ctx, stmts)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_stmts\u001b[39m(ctx, stmts):\n\u001b[0;32m--> 196\u001b[0m     stmts \u001b[38;5;241m=\u001b[39m [\u001b[43mbuild_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m stmts]\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, stmts))\n",
      "File \u001b[0;32m~/miniconda3/envs/img/lib/python3.12/site-packages/torch/jit/frontend.py:406\u001b[0m, in \u001b[0;36mBuilder.__call__\u001b[0;34m(self, ctx, node)\u001b[0m\n\u001b[1;32m    404\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m node\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedNodeError(ctx, node)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(ctx, node)\n",
      "\u001b[0;31mUnsupportedNodeError\u001b[0m: function definitions aren't supported:\n  File \"/private/home/pfz/09-videoseal/videoseal-dev/videoseal/modules/unet.py\", line 206\n    \n        # Upward path\n        def concat_skip_connect(x): return torch.cat(\n        ~~~ <--- HERE\n            (x, hiddens.pop() * self.connect_scale), dim=1)\n        for ublock in self.ups:\n"
     ]
    }
   ],
   "source": [
    "embedder = EmbedderWrapper(wam)\n",
    "\n",
    "# save\n",
    "torch.jit.save(torch.jit.script(embedder), f\"{base_output_dir}/embedder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
